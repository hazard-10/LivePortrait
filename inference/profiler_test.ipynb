{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           aten::cudnn_batch_norm        26.52%       1.931ms        31.78%       2.314ms     115.700us       1.424ms        19.54%       2.426ms     121.300us           0 b           0 b      49.72 Mb       1.00 Kb            20  \n",
      "          aten::cudnn_convolution        10.74%     782.000us        10.74%     782.000us      39.100us       1.410ms        19.35%       1.410ms      70.500us           0 b           0 b      54.51 Mb      54.51 Mb            20  \n",
      "                  model_inference        25.72%       1.873ms       100.00%       7.281ms       7.281ms       1.241ms        17.03%       7.288ms       7.288ms           0 b           0 b           0 b    -110.47 Mb             1  \n",
      "                      aten::empty         1.33%      97.000us         1.33%      97.000us       0.970us     569.000us         7.81%     569.000us       5.690us           0 b           0 b      49.72 Mb      49.72 Mb           100  \n",
      "                       aten::add_         4.89%     356.000us         4.89%     356.000us      12.714us     363.000us         4.98%     363.000us      12.964us           0 b           0 b           0 b           0 b            28  \n",
      "                 aten::empty_like         3.64%     265.000us         4.41%     321.000us      16.050us     328.000us         4.50%     452.000us      22.600us           0 b           0 b      49.68 Mb           0 b            20  \n",
      "     aten::_batch_norm_impl_index         3.98%     290.000us        35.76%       2.604ms     130.200us     304.000us         4.17%       2.730ms     136.500us           0 b           0 b      49.72 Mb           0 b            20  \n",
      "                      aten::relu_         3.26%     237.000us         5.33%     388.000us      22.824us     265.000us         3.64%     471.000us      27.706us           0 b           0 b           0 b           0 b            17  \n",
      "               aten::_convolution         4.33%     315.000us        15.07%       1.097ms      54.850us     236.000us         3.24%       1.646ms      82.300us           0 b           0 b      48.57 Mb      -5.94 Mb            20  \n",
      "                aten::convolution         4.04%     294.000us        19.10%       1.391ms      69.550us     234.000us         3.21%       1.880ms      94.000us           0 b           0 b      48.57 Mb           0 b            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.281ms\n",
      "Self CUDA time total: 7.288ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA, ProfilerActivity.XPU]\n",
    "sort_by_keyword = \"self_\" + device + \"_time_total\"\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "inputs = torch.randn(5, 3, 224, 224).to(device)\n",
    "\n",
    "with profile(activities=activities, profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        30.54%       2.473ms       100.00%       8.098ms       8.098ms       1.558ms        19.21%       8.109ms       8.109ms           0 b           0 b           0 b    -109.13 Mb             1  \n",
      "           aten::cudnn_batch_norm        27.01%       2.187ms        31.50%       2.551ms     127.550us       1.974ms        24.34%       3.067ms     153.350us           0 b           0 b      48.61 Mb         512 b            20  \n",
      "          aten::cudnn_convolution         9.94%     805.000us         9.94%     805.000us      40.250us       1.487ms        18.34%       1.487ms      74.350us           0 b           0 b      53.35 Mb      53.35 Mb            20  \n",
      "     aten::_batch_norm_impl_index         3.77%     305.000us        35.27%       2.856ms     142.800us     280.000us         3.45%       3.347ms     167.350us           0 b           0 b      48.61 Mb           0 b            20  \n",
      "                       aten::add_         3.70%     300.000us         3.70%     300.000us      10.714us     277.000us         3.42%     277.000us       9.893us           0 b           0 b           0 b           0 b            28  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 8.098ms\n",
      "Self CUDA time total: 8.109ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "sort_by_keyword = \"self_\" + device + \"_time_total\"\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "inputs = torch.randn(5, 3, 224, 224).to(device)\n",
    "\n",
    "with profile(activities=activities, with_stack=True, profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "# prof.export_chrome_trace(\"trace.json\")\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
