{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\fp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import tyro\n",
    "import time\n",
    "import imageio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from rich.progress import track\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live Portrait\n",
    "from src.config.argument_config import ArgumentConfig\n",
    "from src.config.inference_config import InferenceConfig\n",
    "from src.config.crop_config import CropConfig\n",
    "from src.utils.helper import load_model, concat_feat\n",
    "from src.utils.camera import headpose_pred_to_degree, get_rotation_matrix\n",
    "from src.utils.retargeting_utils import calc_eye_close_ratio, calc_lip_close_ratio\n",
    "from src.utils.cropper import Cropper\n",
    "from src.utils.video import images2video, concat_frames, get_fps, add_audio_to_video, has_audio_stream\n",
    "from src.utils.crop import _transform_img, prepare_paste_back, paste_back\n",
    "from src.utils.io import load_image_rgb, load_video, resize_to_limit, dump, load\n",
    "from src.utils.helper import mkdir, basename, dct2device, is_video, is_template, remove_suffix, is_image\n",
    "from src.utils.filter import smooth\n",
    "\n",
    "# DiT\n",
    "from audio_dit.inference import InferenceManager, get_model\n",
    "from audio_dit.dataset import load_and_process_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio model\n",
    "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "FRAME_RATE = 25\n",
    "SECTION_LENGTH = 3\n",
    "OVERLAP = 10\n",
    "\n",
    "DB_ROOT = 'vox2-audio-tx'\n",
    "LOG = 'log'\n",
    "AUDIO = 'audio/audio'\n",
    "OUTPUT_DIR = 'audio_encoder_output'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# DiT model\n",
    "config_path = 'D:/Projects/Upenn_CIS_5650/final-project/config/config.json'\n",
    "weight_path = 'D:/Projects/Upenn_CIS_5650/final-project/config/model.pth'\n",
    "\n",
    "# input\n",
    "input_image_path = 'D:/Projects/Upenn_CIS_5650/final-project/data/img/test4.jpg'\n",
    "input_audio_path = 'D:/Projects/Upenn_CIS_5650/final-project/data/audio/test3.wav'\n",
    "\n",
    "# output\n",
    "output_no_audio_path = 'D:/Projects/Upenn_CIS_5650/final-project/LivePortrait/inference/animations/test5_no_audio.mp4'\n",
    "output_video = 'D:/Projects/Upenn_CIS_5650/final-project/LivePortrait/inference/animations/test5_with_audio.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[14:13:34] </span>LandmarkRunner warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>385s                                                 <a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\landmark_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">landmark_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\landmark_runner.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[14:13:34]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m1.\u001b[0m385s                                                 \u001b]8;id=622979;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\landmark_runner.py\u001b\\\u001b[2mlandmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=218338;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[14:13:35] </span>FaceAnalysisDIY warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>024s                                              <a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\face_analysis_diy.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">face_analysis_diy.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\face_analysis_diy.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[14:13:35]\u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m1.\u001b[0m024s                                              \u001b]8;id=832097;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=417748;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Live Portrait Pipeline\n",
    "\n",
    "def partial_fields(target_class, kwargs):\n",
    "    return target_class(**{k: v for k, v in kwargs.items() if hasattr(target_class, k)})\n",
    "\n",
    "args = ArgumentConfig()\n",
    "inference_cfg = partial_fields(InferenceConfig, args.__dict__)\n",
    "crop_cfg = partial_fields(CropConfig, args.__dict__)\n",
    "print(\"Compile complete\")\n",
    "\n",
    "'''\n",
    "Util functions\n",
    "'''\n",
    "\n",
    "def calculate_distance_ratio(lmk: np.ndarray, idx1: int, idx2: int, idx3: int, idx4: int, eps: float = 1e-6) -> np.ndarray:\n",
    "    return (np.linalg.norm(lmk[:, idx1] - lmk[:, idx2], axis=1, keepdims=True) /\n",
    "            (np.linalg.norm(lmk[:, idx3] - lmk[:, idx4], axis=1, keepdims=True) + eps))\n",
    "\n",
    "\n",
    "def calc_eye_close_ratio(lmk: np.ndarray, target_eye_ratio: np.ndarray = None) -> np.ndarray:\n",
    "    lefteye_close_ratio = calculate_distance_ratio(lmk, 6, 18, 0, 12)\n",
    "    righteye_close_ratio = calculate_distance_ratio(lmk, 30, 42, 24, 36)\n",
    "    if target_eye_ratio is not None:\n",
    "        return np.concatenate([lefteye_close_ratio, righteye_close_ratio, target_eye_ratio], axis=1)\n",
    "    else:\n",
    "        return np.concatenate([lefteye_close_ratio, righteye_close_ratio], axis=1)\n",
    "\n",
    "\n",
    "def calc_lip_close_ratio(lmk: np.ndarray) -> np.ndarray:\n",
    "    return calculate_distance_ratio(lmk, 90, 102, 48, 66)\n",
    "\n",
    "def calc_ratio(lmk_lst):\n",
    "    input_eye_ratio_lst = []\n",
    "    input_lip_ratio_lst = []\n",
    "    for lmk in lmk_lst:\n",
    "        # for eyes retargeting\n",
    "        input_eye_ratio_lst.append(calc_eye_close_ratio(lmk[None]))\n",
    "        # for lip retargeting\n",
    "        input_lip_ratio_lst.append(calc_lip_close_ratio(lmk[None]))\n",
    "    return input_eye_ratio_lst, input_lip_ratio_lst\n",
    "\n",
    "def prepare_videos_(imgs, device):\n",
    "    \"\"\" construct the input as standard\n",
    "    imgs: NxHxWx3, uint8\n",
    "    \"\"\"\n",
    "    if isinstance(imgs, list):\n",
    "        _imgs = np.array(imgs)\n",
    "    elif isinstance(imgs, np.ndarray):\n",
    "        _imgs = imgs\n",
    "    else:\n",
    "        raise ValueError(f'imgs type error: {type(imgs)}')\n",
    "\n",
    "    # y = _imgs.astype(np.float32) / 255.\n",
    "    y = _imgs\n",
    "    y = torch.from_numpy(y).permute(0, 3, 1, 2)  # NxHxWx3 -> Nx3xHxW\n",
    "    y = y.to(device)\n",
    "    y = y / 255.\n",
    "    y = torch.clamp(y, 0, 1)\n",
    "\n",
    "    return y\n",
    "\n",
    "def get_kp_info(x: torch.Tensor, **kwargs) -> dict:\n",
    "    \"\"\" get the implicit keypoint information\n",
    "    x: Bx3xHxW, normalized to 0~1\n",
    "    flag_refine_info: whether to trandform the pose to degrees and the dimention of the reshape\n",
    "    return: A dict contains keys: 'pitch', 'yaw', 'roll', 't', 'exp', 'scale', 'kp'\n",
    "    \"\"\"\n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16,\n",
    "                                 enabled=inference_cfg.flag_use_half_precision):\n",
    "        kp_info = motion_extractor(x)\n",
    "\n",
    "        if inference_cfg.flag_use_half_precision:\n",
    "            # float the dict\n",
    "            for k, v in kp_info.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    kp_info[k] = v.float()\n",
    "\n",
    "    flag_refine_info: bool = kwargs.get('flag_refine_info', True)\n",
    "    if flag_refine_info:\n",
    "        bs = kp_info['kp'].shape[0]\n",
    "        kp_info['pitch'] = headpose_pred_to_degree(kp_info['pitch'])[:, None]  # Bx1\n",
    "        kp_info['yaw'] = headpose_pred_to_degree(kp_info['yaw'])[:, None]  # Bx1\n",
    "        kp_info['roll'] = headpose_pred_to_degree(kp_info['roll'])[:, None]  # Bx1\n",
    "        kp_info['kp'] = kp_info['kp'].reshape(bs, -1, 3)  # BxNx3\n",
    "        kp_info['exp'] = kp_info['exp'].reshape(bs, -1, 3)  # BxNx3\n",
    "\n",
    "    return kp_info\n",
    "\n",
    "def read_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frames = []\n",
    "    for _ in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (256, 256))  # Resize to 256x256\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return video_path, frames\n",
    "\n",
    "def read_multiple_videos(video_paths, num_threads=4):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = list(executor.map(read_video_frames, video_paths))\n",
    "    return results\n",
    "\n",
    "def euler_to_quaternion(pitch, yaw, roll):\n",
    "    cy = torch.cos(yaw * 0.5)\n",
    "    sy = torch.sin(yaw * 0.5)\n",
    "    cp = torch.cos(pitch * 0.5)\n",
    "    sp = torch.sin(pitch * 0.5)\n",
    "    cr = torch.cos(roll * 0.5)\n",
    "    sr = torch.sin(roll * 0.5)\n",
    "\n",
    "    w = cr * cp * cy + sr * sp * sy\n",
    "    x = sr * cp * cy - cr * sp * sy\n",
    "    y = cr * sp * cy + sr * cp * sy\n",
    "    z = cr * cp * sy - sr * sp * cy\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "def quaternion_to_euler(q):\n",
    "    \"\"\"\n",
    "    Convert quaternion to Euler angles (pitch, yaw, roll) in radians.\n",
    "    q: torch.Tensor of shape (..., 4) representing quaternions (w, x, y, z)\n",
    "    Returns: tuple of (pitch, yaw, roll) as torch.Tensor\n",
    "    \"\"\"\n",
    "    # Extract the values from q\n",
    "    w, x, y, z = q[..., 0], q[..., 1], q[..., 2], q[..., 3]\n",
    "\n",
    "    # Roll (x-axis rotation)\n",
    "    sinr_cosp = 2 * (w * x + y * z)\n",
    "    cosr_cosp = 1 - 2 * (x * x + y * y)\n",
    "    roll = torch.atan2(sinr_cosp, cosr_cosp)\n",
    "\n",
    "    # Pitch (y-axis rotation)\n",
    "    sinp = 2 * (w * y - z * x)\n",
    "    pitch = torch.where(\n",
    "        torch.abs(sinp) >= 1,\n",
    "        torch.sign(sinp) * torch.pi / 2,\n",
    "        torch.asin(sinp)\n",
    "    )\n",
    "\n",
    "    # Yaw (z-axis rotation)\n",
    "    siny_cosp = 2 * (w * z + x * y)\n",
    "    cosy_cosp = 1 - 2 * (y * y + z * z)\n",
    "    yaw = torch.atan2(siny_cosp, cosy_cosp)\n",
    "\n",
    "    return pitch, yaw, roll\n",
    "\n",
    "def quaternion_to_euler_degrees(q):\n",
    "    \"\"\"\n",
    "    Convert quaternion to Euler angles (pitch, yaw, roll) in degrees.\n",
    "    q: torch.Tensor of shape (..., 4) representing quaternions (w, x, y, z)\n",
    "    Returns: tuple of (pitch, yaw, roll) as torch.Tensor in degrees\n",
    "    \"\"\"\n",
    "    pitch, yaw, roll = quaternion_to_euler(q)\n",
    "    return torch.rad2deg(pitch), torch.rad2deg(yaw), torch.rad2deg(roll)\n",
    "\n",
    "\n",
    "'''\n",
    "Loading source related modules\n",
    "'''\n",
    "def prepare_source(img: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\" construct the input as standard\n",
    "    img: HxWx3, uint8, 256x256\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x = img.copy()\n",
    "\n",
    "    if x.ndim == 3:\n",
    "        x = x[np.newaxis].astype(np.float32) / 255.  # HxWx3 -> 1xHxWx3, normalized to 0~1\n",
    "    elif x.ndim == 4:\n",
    "        x = x.astype(np.float32) / 255.  # BxHxWx3, normalized to 0~1\n",
    "    else:\n",
    "        raise ValueError(f'img ndim should be 3 or 4: {x.ndim}')\n",
    "    x = np.clip(x, 0, 1)  # clip to 0~1\n",
    "    x = torch.from_numpy(x).permute(0, 3, 1, 2)  # 1xHxWx3 -> 1x3xHxW\n",
    "    x = x.to(device)\n",
    "    return x\n",
    "\n",
    "def warp_decode(feature_3d: torch.Tensor, kp_source: torch.Tensor, kp_driving: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\" get the image after the warping of the implicit keypoints\n",
    "    feature_3d: Bx32x16x64x64, feature volume\n",
    "    kp_source: BxNx3\n",
    "    kp_driving: BxNx3\n",
    "    \"\"\"\n",
    "    # The line 18 in Algorithm 1: D(W(f_s; x_s, x′_d,i)）\n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16,\n",
    "                                 enabled=inference_cfg.flag_use_half_precision):\n",
    "        # get decoder input\n",
    "        ret_dct = warping_module(feature_3d, kp_source=kp_source, kp_driving=kp_driving)\n",
    "        # decode\n",
    "        ret_dct['out'] = spade_generator(feature=ret_dct['out'])\n",
    "\n",
    "    return ret_dct\n",
    "\n",
    "def extract_feature_3d( x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\" get the appearance feature of the image by F\n",
    "    x: Bx3xHxW, normalized to 0~1\n",
    "    \"\"\"\n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16,\n",
    "                                 enabled=inference_cfg.flag_use_half_precision):\n",
    "        feature_3d = appearance_feature_extractor(x)\n",
    "\n",
    "    return feature_3d.float()\n",
    "\n",
    "def transform_keypoint(kp_info: dict):\n",
    "    \"\"\"\n",
    "    transform the implicit keypoints with the pose, shift, and expression deformation\n",
    "    kp: BxNx3\n",
    "    \"\"\"\n",
    "    kp = kp_info['kp']    # (bs, k, 3)\n",
    "    pitch, yaw, roll = kp_info['pitch'], kp_info['yaw'], kp_info['roll']\n",
    "\n",
    "    t, exp = kp_info['t'], kp_info['exp']\n",
    "    scale = kp_info['scale']\n",
    "\n",
    "    pitch = headpose_pred_to_degree(pitch)\n",
    "    yaw = headpose_pred_to_degree(yaw)\n",
    "    roll = headpose_pred_to_degree(roll)\n",
    "\n",
    "    bs = kp.shape[0]\n",
    "    if kp.ndim == 2:\n",
    "        num_kp = kp.shape[1] // 3  # Bx(num_kpx3)\n",
    "    else:\n",
    "        num_kp = kp.shape[1]  # Bxnum_kpx3\n",
    "\n",
    "    rot_mat = get_rotation_matrix(pitch, yaw, roll)    # (bs, 3, 3)\n",
    "\n",
    "    # Eqn.2: s * (R * x_c,s + exp) + t\n",
    "    kp_transformed = kp.view(bs, num_kp, 3) @ rot_mat + exp.view(bs, num_kp, 3)\n",
    "    kp_transformed *= scale[..., None]  # (bs, k, 3) * (bs, 1, 1) = (bs, k, 3)\n",
    "    kp_transformed[:, :, 0:2] += t[:, None, 0:2]  # remove z, only apply tx ty\n",
    "\n",
    "    return kp_transformed\n",
    "\n",
    "def parse_output(out: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\" construct the output as standard\n",
    "    return: 1xHxWx3, uint8\n",
    "    \"\"\"\n",
    "    out = np.transpose(out.data.cpu().numpy(), [0, 2, 3, 1])  # 1x3xHxW -> 1xHxWx3\n",
    "    out = np.clip(out, 0, 1)  # clip to 0~1\n",
    "    out = np.clip(out * 255, 0, 255).astype(np.uint8)  # 0~1 -> 0~255\n",
    "\n",
    "    return out\n",
    "'''\n",
    "Main module for inference\n",
    "'''\n",
    "model_config = yaml.load(open(inference_cfg.models_config, 'r'), Loader=yaml.SafeLoader)\n",
    "# init F\n",
    "appearance_feature_extractor = load_model(inference_cfg.checkpoint_F, model_config, device, 'appearance_feature_extractor')\n",
    "# init M\n",
    "motion_extractor = load_model(inference_cfg.checkpoint_M, model_config, device, 'motion_extractor')\n",
    "# init W\n",
    "warping_module = load_model(inference_cfg.checkpoint_W, model_config, device, 'warping_module')\n",
    "# init G\n",
    "spade_generator = load_model(inference_cfg.checkpoint_G, model_config, device, 'spade_generator')\n",
    "# init S and R\n",
    "if inference_cfg.checkpoint_S is not None and os.path.exists(inference_cfg.checkpoint_S):\n",
    "    stitching_retargeting_module = load_model(inference_cfg.checkpoint_S, model_config, device, 'stitching_retargeting_module')\n",
    "else:\n",
    "    stitching_retargeting_module = None\n",
    "\n",
    "cropper = Cropper(crop_cfg=crop_cfg, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.0.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.0.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.0.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.0.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.1.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.1.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.1.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.1.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.2.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.2.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.2.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.2.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.3.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.3.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.3.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.3.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.4.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.4.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.4.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.encoder.down_blocks.4.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.0.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.0.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.0.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.0.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.1.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.1.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.1.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.1.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.2.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.2.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.2.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.2.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.3.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.3.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.3.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.3.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.4.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.4.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.4.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.up_blocks.4.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.conv.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.conv.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.hourglass.decoder.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.mask.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.mask.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.compress.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.compress.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.norm.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.norm.bias is on device: cuda:0\n",
      "Parameter dense_motion_network.occlusion.weight is on device: cuda:0\n",
      "Parameter dense_motion_network.occlusion.bias is on device: cuda:0\n",
      "Parameter third.conv.weight is on device: cuda:0\n",
      "Parameter third.conv.bias is on device: cuda:0\n",
      "Parameter third.norm.weight is on device: cuda:0\n",
      "Parameter third.norm.bias is on device: cuda:0\n",
      "Parameter fourth.weight is on device: cuda:0\n",
      "Parameter fourth.bias is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda')  # Replace 'cuda' with 'cpu' if checking for CPU\n",
    "# model_on_device = all(param.device == device for param in model.parameters())\n",
    "# print(f\"Is the model on {device}? {model_on_device}\")\n",
    "\n",
    "for name, param in warping_module.named_parameters():\n",
    "    print(f\"Parameter {name} is on device: {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter fc.weight is on device: cuda:0\n",
      "Parameter fc.bias is on device: cuda:0\n",
      "Parameter G_middle_0.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_0.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_0.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_0.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_0.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_1.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_1.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_1.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_1.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_1.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_2.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_2.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_2.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_2.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_2.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_3.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_3.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_3.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_3.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_3.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_4.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_4.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_4.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_4.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_4.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_5.conv_0.bias is on device: cuda:0\n",
      "Parameter G_middle_5.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_5.conv_1.bias is on device: cuda:0\n",
      "Parameter G_middle_5.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter G_middle_5.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_0.conv_0.bias is on device: cuda:0\n",
      "Parameter up_0.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter up_0.conv_1.bias is on device: cuda:0\n",
      "Parameter up_0.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter up_0.conv_s.weight_orig is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_0.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_0.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_0.norm_s.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_1.conv_0.bias is on device: cuda:0\n",
      "Parameter up_1.conv_0.weight_orig is on device: cuda:0\n",
      "Parameter up_1.conv_1.bias is on device: cuda:0\n",
      "Parameter up_1.conv_1.weight_orig is on device: cuda:0\n",
      "Parameter up_1.conv_s.weight_orig is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_1.norm_0.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_1.norm_1.mlp_beta.bias is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_shared.0.weight is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_shared.0.bias is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_gamma.weight is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_gamma.bias is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_beta.weight is on device: cuda:0\n",
      "Parameter up_1.norm_s.mlp_beta.bias is on device: cuda:0\n",
      "Parameter conv_img.0.weight is on device: cuda:0\n",
      "Parameter conv_img.0.bias is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in spade_generator.named_parameters():\n",
    "    print(f\"Parameter {name} is on device: {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Audio Pipeline\n",
    "\n",
    "# Move model and processor to global scope\n",
    "wav2vec_model = Wav2Vec2Model.from_pretrained(MODEL_NAME).to(device)\n",
    "wav2vec_processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def read_multiple_audios(paths, num_threads=12):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = list(executor.map(load_and_process_audio, paths))\n",
    "    return results\n",
    "\n",
    "\n",
    "def read_json_and_form_paths(data,id_key):\n",
    "    filenames=[]\n",
    "    file_paths = []\n",
    "\n",
    "    # Iterate through the nested structure\n",
    "    for id_key, id_value in data.items():\n",
    "        os.makedirs(os.path.join(DB_ROOT,OUTPUT_DIR,id_key), exist_ok=True)\n",
    "        for url_key, url_value in id_value.items():\n",
    "            for clip_id in url_value.keys():\n",
    "                # Form the file path\n",
    "                file_path = os.path.join(DB_ROOT,AUDIO,id_key, url_key, clip_id.replace('.txt', '.wav'))\n",
    "                file_name = os.path.join(DB_ROOT,OUTPUT_DIR,id_key, url_key+'+'+clip_id.replace('.txt', ''))\n",
    "                filenames.append(file_name)\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    return file_paths, filenames\n",
    "\n",
    "def load_and_process_audio(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    original_sample_rate = sample_rate\n",
    "\n",
    "    if sample_rate != TARGET_SAMPLE_RATE:\n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, TARGET_SAMPLE_RATE)\n",
    "\n",
    "    # Convert to mono if stereo\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "    print(file_path,\" waveform.shape \",waveform.shape)\n",
    "\n",
    "    # Calculate section length and overlap in samples\n",
    "    section_samples = SECTION_LENGTH * 16027\n",
    "    overlap_samples = int(OVERLAP / FRAME_RATE * TARGET_SAMPLE_RATE)\n",
    "    print('section_samples',section_samples,'overlap_samples',overlap_samples)\n",
    "\n",
    "    # Pad if shorter than 3 seconds\n",
    "    if waveform.shape[1] < section_samples:\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, section_samples - waveform.shape[1]))\n",
    "        return [waveform.squeeze(0)], original_sample_rate\n",
    "\n",
    "    # Split into sections with overlap\n",
    "    sections = []\n",
    "    start = 0\n",
    "\n",
    "    print('starting to segment', file_path)\n",
    "    while start < waveform.shape[1]:\n",
    "        end = start + section_samples\n",
    "        if end >= waveform.shape[1]:\n",
    "            tmp=waveform[:, start:min(end, waveform.shape[1])]\n",
    "            tmp = torch.nn.functional.pad(tmp, (0, section_samples - tmp.shape[1]))\n",
    "            sections.append(tmp.squeeze(0))\n",
    "            print(tmp.shape)\n",
    "            break\n",
    "        else:\n",
    "            sections.append(waveform[:, start:min(end, waveform.shape[1])].squeeze(0))\n",
    "\n",
    "        start = int(end - overlap_samples)\n",
    "\n",
    "\n",
    "    return file_path, sections\n",
    "\n",
    "def inference_process_wav_file(path):\n",
    "    audio_path, segments = load_and_process_audio(path)\n",
    "    print(audio_path,segments)\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    inputs = wav2vec_processor(segments, sampling_rate=TARGET_SAMPLE_RATE, return_tensors=\"pt\", padding=True).input_values.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = wav2vec_model(inputs)\n",
    "        latent = outputs.last_hidden_state\n",
    "\n",
    "        seq_length = latent.shape[1]\n",
    "        new_seq_length = int(seq_length * (FRAME_RATE / 50))\n",
    "\n",
    "        latent_features_interpolated = F.interpolate(latent.transpose(1,2),\n",
    "                                                     size=new_seq_length,\n",
    "                                                     mode='linear',\n",
    "                                                     align_corners=True).transpose(1,2)\n",
    "    return latent_features_interpolated\n",
    "\n",
    "\n",
    "def process_wav_file(paths, output_paths, uid):\n",
    "    device = torch.device(f\"cuda\")\n",
    "\n",
    "    model = Wav2Vec2Model.from_pretrained(MODEL_NAME).to(device)\n",
    "    processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    read_2_gpu_batch_size = 2048\n",
    "    gpu_batch_size = BATCH_SIZE\n",
    "    process_queue = torch.Tensor().to(device)\n",
    "\n",
    "    audio_segments = read_multiple_audios(paths, num_threads=4)\n",
    "    all_segments = []\n",
    "    total_segments = 0\n",
    "\n",
    "    audio_lengths = []\n",
    "    output_fns = []\n",
    "\n",
    "    for (audio_path, segments), output_fn in zip(audio_segments,output_paths):\n",
    "        all_segments.extend(segments)\n",
    "        segment_count = len(segments)\n",
    "        total_segments += segment_count\n",
    "        audio_lengths.append(segment_count)\n",
    "\n",
    "        output_fns.append(output_fn)\n",
    "\n",
    "    all_segments = np.array(all_segments)\n",
    "    print(all_segments.size)\n",
    "\n",
    "    read_data_2_gpu_pointer = 0\n",
    "    pbar = tqdm(total=total_segments, desc=f\"Processing {uid}\")\n",
    "\n",
    "    while read_data_2_gpu_pointer < total_segments:\n",
    "        current_batch_size = min(read_2_gpu_batch_size, total_segments - read_data_2_gpu_pointer)\n",
    "\n",
    "        batch_input = all_segments[read_data_2_gpu_pointer:read_data_2_gpu_pointer + current_batch_size]\n",
    "\n",
    "        mini_batch_start = 0\n",
    "        all_info = []\n",
    "        while mini_batch_start < batch_input.shape[0]:\n",
    "            mini_batch_end = min(mini_batch_start + gpu_batch_size, batch_input.shape[0])\n",
    "            mini_batch = batch_input[mini_batch_start:mini_batch_end]\n",
    "\n",
    "            inputs = processor(mini_batch, sampling_rate=TARGET_SAMPLE_RATE, return_tensors=\"pt\", padding=True).input_values.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "            latent = outputs.last_hidden_state\n",
    "            print('latent',latent.shape)\n",
    "            seq_length = latent.shape[1]\n",
    "            new_seq_length = int(seq_length * (FRAME_RATE / 50))  # Assuming Wav2Vec2 outputs at ~50Hz\n",
    "\n",
    "            latent_features_interpolated = F.interpolate(latent.transpose(1,2),\n",
    "                                                            size=new_seq_length,\n",
    "                                                            mode='linear',\n",
    "                                                            align_corners=True).transpose(1,2)\n",
    "            print('latent_features_interpolated',latent_features_interpolated.shape)\n",
    "            all_info.append(latent_features_interpolated)\n",
    "\n",
    "            mini_batch_start = mini_batch_end\n",
    "        all_info_tensor = torch.cat(all_info, dim=0)\n",
    "\n",
    "        process_queue = torch.cat((process_queue, all_info_tensor), dim=0)\n",
    "\n",
    "        print(audio_lengths)\n",
    "        while len(output_fns) > 0 and len(process_queue) >= audio_lengths[0]:\n",
    "            current_output_fn = output_fns[0]\n",
    "            current_segment_count = audio_lengths[0]\n",
    "\n",
    "            audio_tensor = process_queue[:current_segment_count]\n",
    "            np.save(current_output_fn, audio_tensor.cpu().numpy())\n",
    "            print('save',current_output_fn)\n",
    "            process_queue = process_queue[current_segment_count:]\n",
    "            output_fns.pop(0)\n",
    "            audio_lengths.pop(0)\n",
    "\n",
    "\n",
    "        read_data_2_gpu_pointer += current_batch_size\n",
    "        pbar.update(current_batch_size)\n",
    "\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_path exists: True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DiffLiveHead:\n\tUnexpected key(s) in state_dict: \"start_audio_feat\", \"start_motion_feat\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_path exists:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config_path))\n\u001b[0;32m      4\u001b[0m audio_model_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(config_path))\n\u001b[1;32m----> 5\u001b[0m inference_manager \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\audio_dit\\inference.py:140\u001b[0m, in \u001b[0;36mget_model\u001b[1;34m(config_path, checkpoint_path, device)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInferenceManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\audio_dit\\inference.py:26\u001b[0m, in \u001b[0;36mInferenceManager.__init__\u001b[1;34m(self, config_path, checkpoint_path, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model()\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\audio_dit\\inference.py:78\u001b[0m, in \u001b[0;36mInferenceManager.load_checkpoint\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m     75\u001b[0m         new_state_dict[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Load the state dictionary into the model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel checkpoint loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\fp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DiffLiveHead:\n\tUnexpected key(s) in state_dict: \"start_audio_feat\", \"start_motion_feat\". "
     ]
    }
   ],
   "source": [
    "# DiT Model\n",
    "\n",
    "print(\"config_path exists:\", os.path.exists(config_path))\n",
    "audio_model_config = json.load(open(config_path))\n",
    "inference_manager = get_model(config_path, weight_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10:08:54] </span>More than one face detected in the image, only pick one face by rule large-small.         <a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\cropper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cropper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\cropper.py#131\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10:08:54]\u001b[0m\u001b[2;36m \u001b[0mMore than one face detected in the image, only pick one face by rule large-small.         \u001b]8;id=40223;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\cropper.py\u001b\\\u001b[2mcropper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=729647;file://d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\src\\utils\\cropper.py#131\u001b\\\u001b[2m131\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_s shape torch.Size([1, 3, 256, 256])\n",
      "x_c_s shape torch.Size([1, 21, 3])\n",
      "x_s shape torch.Size([1, 21, 3])\n",
      "f_s shape torch.Size([1, 32, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Process Input Image\n",
    "\n",
    "img_rgb = load_image_rgb(input_image_path)\n",
    "source_rgb_lst = [img_rgb]\n",
    "\n",
    "source_lmk = cropper.calc_lmk_from_cropped_image(source_rgb_lst[0])\n",
    "img_crop_256x256 = cv2.resize(source_rgb_lst[0], (256, 256))  # force to resize to 256x256\n",
    "\n",
    "I_s = prepare_source(img_crop_256x256)\n",
    "x_s_info = get_kp_info(I_s)\n",
    "x_c_s = x_s_info['kp']\n",
    "x_s = transform_keypoint(x_s_info)\n",
    "f_s = extract_feature_3d(I_s)\n",
    "\n",
    "print(f\"I_s shape {I_s.shape}\")\n",
    "print(f\"x_c_s shape {x_c_s.shape}\")\n",
    "print(f\"x_s shape {x_s.shape}\")\n",
    "print(f\"f_s shape {f_s.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Projects/Upenn_CIS_5650/final-project/data/audio/test3.wav  waveform.shape  torch.Size([1, 60338])\n",
      "section_samples 48081 overlap_samples 6400\n",
      "starting to segment D:/Projects/Upenn_CIS_5650/final-project/data/audio/test3.wav\n",
      "torch.Size([1, 48081])\n",
      "D:/Projects/Upenn_CIS_5650/final-project/data/audio/test3.wav [tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0016, -0.0016, -0.0016]), tensor([-0.0778, -0.0795, -0.0818,  ...,  0.0000,  0.0000,  0.0000])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JackeyTY\\AppData\\Local\\Temp\\ipykernel_1156904\\1265674379.py:3: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "d:\\Projects\\Upenn_CIS_5650\\final-project\\LivePortrait\\fp\\Lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:863: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process Input Audio\n",
    "\n",
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "custom_audio_latent = inference_process_wav_file(input_audio_path)\n",
    "\n",
    "custom_audio_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 7, 22, 33, 34, 40, 43, 45, 46, 48, 51, 52, 53, 57, 58, 59, 60, 61, 62] [-0.05029296875, 0.0857086181640625, -0.07587742805480957, 0.058624267578125, -0.0004341602325439453, 0.00019466876983642578, -0.038482666015625, 0.0345458984375, -0.030120849609375, 0.038360595703125, -3.0279159545898438e-05, 1.3887882232666016e-05, -0.0364990234375, 0.036102294921875, -0.043212890625, 0.046844482421875, -4.3332576751708984e-05, 1.8775463104248047e-05, -0.03326416015625, 0.057373046875, -0.03460693359375, 0.031707763671875, -0.0001958608627319336, 0.0005192756652832031, -0.0728759765625, 0.0587158203125, -0.04840087890625, 0.039642333984375, -0.00025916099548339844, 0.00048089027404785156, -0.09722900390625, 0.12469482421875, -0.1556396484375, 0.09326171875, -0.00018024444580078125, 0.00037860870361328125, -0.0279384758323431, 0.010650634765625, -0.039306640625, 0.03802490234375, -1.049041748046875e-05, 3.6954879760742188e-06, -0.032989501953125, 0.044281005859375, -0.037261962890625, 0.0433349609375, -0.00022792529489379376, 0.0003247261047363281, -0.0288234855979681, 0.006015777587890625, -0.0108795166015625, 0.0134124755859375, -7.784366607666016e-05, 5.2034854888916016e-05, -0.01531982421875, 0.027801513671875, -0.036041259765625, 0.0242156982421875, -8.83340835571289e-05, 2.6464462280273438e-05, -0.06463623046875, 0.0303802490234375, -0.0446159653365612, 0.03619384765625, -0.02947998046875, 0.030792236328125, -0.0159145500510931, 0.018890380859375, -0.01898193359375, 0.0264739990234375, -6.103515625e-05, 3.266334533691406e-05, -0.0094450069591403, 0.00604248046875, -0.005710510071367025, 0.00557708740234375, -2.866983413696289e-05, 1.4543533325195312e-05, -0.0265350341796875, 0.01186370849609375, -0.0227047111839056, 0.01386260986328125, -0.000133514404296875, 6.687641143798828e-05, -0.01129150390625, 0.01331329345703125, -0.0251922607421875, 0.0195465087890625, -8.285045623779297e-06, 6.079673767089844e-06, -0.0141599727794528, 0.018341064453125, -0.0189971923828125, 0.029296875, -6.049728108337149e-05, 3.057718276977539e-05, -0.01216888427734375, 0.02069091796875, -0.016754150390625, 0.017974853515625, -0.00014078617095947266, 6.842613220214844e-05, -0.01910400390625, 0.016204833984375, -0.025634765625, 0.04150390625, -0.0100250244140625, 0.00991058349609375, -0.005596160888671875, 0.01132965087890625, -0.0269775390625, 0.02166748046875, -0.000362396240234375, 9.059906005859375e-05, -0.0325927734375, 0.038818359375, -0.05877685546875, 0.076416015625, -0.02215576171875, 0.019775390625, -0.0219573974609375, 0.0247344970703125, -0.039764404296875, 0.045, -0.01512908935546875, 0.017730712890625]\n",
      "Audio input shape: torch.Size([2, 65, 768])\n",
      "Audio previous shape: torch.Size([2, 10, 768])\n",
      "torch.Size([1, 65, 20])\n",
      "torch.Size([1, 65, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 65, 20]), torch.Size([1, 10, 20]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Motion\n",
    "\n",
    "used_audio_example = input_audio_path\n",
    "audio_latent = custom_audio_latent\n",
    "\n",
    "audio_latent_input = audio_latent\n",
    "latent_mask_used=audio_model_config['latent_mask_1']\n",
    "latent_bound = audio_model_config['latent_bound']\n",
    "print(latent_mask_used, latent_bound)\n",
    "\n",
    "audio_seq = audio_latent_input[:, 10:, :]\n",
    "audio_prev = audio_latent_input[:, :10, :]\n",
    "\n",
    "print(\"Audio input shape:\", audio_seq.shape)\n",
    "print(\"Audio previous shape:\", audio_prev.shape)\n",
    "\n",
    "motion_prev = torch.zeros(audio_latent.shape[0], 10, 6, device=device)\n",
    "\n",
    "mouth_open_ratio_val = 0.25\n",
    "mouth_open_ratio_input = torch.tensor([mouth_open_ratio_val], device=device).unsqueeze(0)\n",
    "out_motion = torch.tensor([], device=device)\n",
    "B, T, audio_dim = audio_seq.shape\n",
    "motion_dim = audio_model_config['x_dim']\n",
    "shape_in = x_c_s.reshape(1, -1).to(device)\n",
    "this_audio_prev = torch.zeros(1, 10, audio_dim, device=device)\n",
    "this_motion_prev = torch.zeros(1, 10, motion_dim , device=device)\n",
    "motion_prev = torch.zeros(1, 10, motion_dim , device=device)\n",
    "#print(\"Audio input shape:\", audio_seq.shape)\n",
    "#print(out_motion.shape)\n",
    "for batch_index in range(0, audio_seq.shape[0]):\n",
    "    generated_motion = inference_manager.inference(audio_seq[batch_index:batch_index+1],\n",
    "                                                shape_in, this_motion_prev, this_audio_prev,\n",
    "                                                cfg_scale=0.25,\n",
    "                                                mouth_open_ratio = mouth_open_ratio_input,\n",
    "                                                denoising_steps=10)\n",
    "    this_motion_prev = generated_motion[:, -10:, :]\n",
    "    this_audio_prev = audio_seq[batch_index:batch_index+1, -10:, :]\n",
    "\n",
    "    generated_motion = generated_motion - torch.mean(generated_motion, dim=-1, keepdim=True)\n",
    "    out_motion = torch.cat((out_motion, generated_motion), dim=0)\n",
    "    print(generated_motion.shape)\n",
    "    #print(out_motion.shape)\n",
    "\n",
    "generated_motion = out_motion\n",
    "generated_motion.shape, motion_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames\n",
    "\n",
    "# Assuming generated_motion is your output from dit_inference\n",
    "# generated_motion shape: [2, 65, 63]\n",
    "# motion_prev shape: [2, 10, 63]\n",
    "\n",
    "def process_motion_batch(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "    frames = []\n",
    "    B, T, feat_count = gen_motion_batch.shape\n",
    "    full_motion = gen_motion_batch.reshape(B*T, feat_count)\n",
    "    full_motion = torch.cat([motion_prev[0], full_motion], dim=0)\n",
    "\n",
    "    pose = full_motion[:, -5:]\n",
    "    exp = full_motion[:, :]\n",
    "    print(\"pose\", pose.shape, \"exp\", exp.shape)\n",
    "    # exp_mask = torch.zeros_like(full_motion[0][0])\n",
    "    # pos_mouth = [14, 17, 19, 20]\n",
    "    # eye and mouth [15, 16, 18]\n",
    "    # pos_eye & forehead = [1, 2, 11, 12, 13] # 1.z is mouth, 12 small eye\n",
    "    # shape [0, 3, 4, 7, 8, 9, 10] # may include shape dependent pose\n",
    "    # pos_cloth = [5, 6]\n",
    "\n",
    "    # for p in pos_mouth:\n",
    "    #     exp_mask[p * 3:(p + 1) * 3] = 1\n",
    "\n",
    "    # # exp_mask = exp_mask.reshape(21,3)\n",
    "    # print(full_motion[0, 10:15, :] * exp_mask)\n",
    "\n",
    "    t_identity = torch.zeros((1, 3), dtype=torch.float32, device=device)\n",
    "    pitch_identity = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "    yaw_identity = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "    roll_identity = torch.zeros((1), dtype=torch.float32, device=device)\n",
    "    scale_identity = torch.ones((1), dtype=torch.float32, device=device) * 1.5\n",
    "\n",
    "    use_identity_pose = True\n",
    "    if use_identity_pose:\n",
    "        t_s = t_identity\n",
    "        pitch_s = pitch_identity\n",
    "        yaw_s = yaw_identity\n",
    "        roll_s = roll_identity\n",
    "        scale_s = scale_identity\n",
    "    else:\n",
    "        t_s = x_s_info['t']\n",
    "        pitch_s = x_s_info['pitch']\n",
    "        yaw_s = x_s_info['yaw']\n",
    "        roll_s = x_s_info['roll']\n",
    "        scale_s = x_s_info['scale']\n",
    "    t = t_s\n",
    "    pitch = pitch_s\n",
    "    yaw = yaw_s\n",
    "    roll = roll_s\n",
    "    scale = scale_s\n",
    "\n",
    "    full_63_exp = torch.zeros(full_motion.shape[0], 63, device=device)\n",
    "    for i, dim in enumerate(audio_model_config['latent_mask_1']):\n",
    "        print(i, dim)\n",
    "        full_63_exp[:, dim] = exp[:, i]\n",
    "    full_motion = full_63_exp.reshape(-1, 63)\n",
    "\n",
    "    x_d_list = []\n",
    "\n",
    "    for i in tqdm(range(full_motion.shape[0]), desc=\"Generating x_d\"):\n",
    "        motion = full_motion[i].reshape(21, 3)\n",
    "\n",
    "        # Initialize empty tensors\n",
    "\n",
    "        # # Extract values from motion\n",
    "        exp = motion #* exp_mask\n",
    "        # pitch = pose[i, 0:1]\n",
    "        # yaw = pose[i, 1:2]\n",
    "        # roll = pose[i, 2:3]\n",
    "        # t_x = pose[i, 3:4]\n",
    "        # t_y = pose[i, 4:5]\n",
    "        t = torch.tensor(t, device=device)\n",
    "\n",
    "        x_d_i = scale * (x_c_s @ get_rotation_matrix(pitch, yaw, roll) + exp) + t\n",
    "        x_d_list.append(x_d_i.squeeze(0))\n",
    "\n",
    "    x_d_batch = torch.stack(x_d_list, dim=0)\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    frames = []\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "\n",
    "        batch_f_s = f_s_batch[start_idx:end_idx]\n",
    "        batch_x_s = x_s_batch[start_idx:end_idx]\n",
    "        batch_x_d = x_d_batch[start_idx:end_idx]\n",
    "\n",
    "        out = warp_decode_func(batch_f_s, batch_x_s, batch_x_d)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        batch_frames = (out['out'].permute(0, 2, 3, 1).cpu().numpy() * 255).astype(np.uint8)\n",
    "        frames.extend(list(batch_frames))\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"time to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {end_time - middle_time}s\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up...\n",
      "\n",
      "pose torch.Size([140, 5]) exp torch.Size([140, 20])\n",
      "0 4\n",
      "1 6\n",
      "2 7\n",
      "3 22\n",
      "4 33\n",
      "5 34\n",
      "6 40\n",
      "7 43\n",
      "8 45\n",
      "9 46\n",
      "10 48\n",
      "11 51\n",
      "12 52\n",
      "13 53\n",
      "14 57\n",
      "15 58\n",
      "16 59\n",
      "17 60\n",
      "18 61\n",
      "19 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating x_d:   0%|          | 0/140 [00:00<?, ?it/s]C:\\Users\\JackeyTY\\AppData\\Local\\Temp\\ipykernel_132788\\437758918.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "Generating x_d: 100%|██████████| 140/140 [00:00<00:00, 2057.40it/s]\n",
      "Processing batches: 100%|██████████| 35/35 [00:03<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to prep x_d 0:00:00.071558s\n",
      "time to warp and decode 0:00:03.402035s\n",
      "total generation time 0:00:03.473593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Warm up...\\n\")\n",
    "all_frames = process_motion_batch(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without profiiling...\n",
      "\n",
      "pose torch.Size([140, 5]) exp torch.Size([140, 20])\n",
      "0 4\n",
      "1 6\n",
      "2 7\n",
      "3 22\n",
      "4 33\n",
      "5 34\n",
      "6 40\n",
      "7 43\n",
      "8 45\n",
      "9 46\n",
      "10 48\n",
      "11 51\n",
      "12 52\n",
      "13 53\n",
      "14 57\n",
      "15 58\n",
      "16 59\n",
      "17 60\n",
      "18 61\n",
      "19 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating x_d:   0%|          | 0/140 [00:00<?, ?it/s]C:\\Users\\JackeyTY\\AppData\\Local\\Temp\\ipykernel_153884\\3033579522.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "Generating x_d: 100%|██████████| 140/140 [00:00<00:00, 2058.09it/s]\n",
      "Processing batches: 100%|██████████| 35/35 [00:03<00:00, 10.68it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Without profiiling...\\n\")\n",
    "all_frames = process_motion_batch(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling...\n",
      "\n",
      "pose torch.Size([140, 5]) exp torch.Size([140, 20])\n",
      "0 4\n",
      "1 6\n",
      "2 7\n",
      "3 22\n",
      "4 33\n",
      "5 34\n",
      "6 40\n",
      "7 43\n",
      "8 45\n",
      "9 46\n",
      "10 48\n",
      "11 51\n",
      "12 52\n",
      "13 53\n",
      "14 57\n",
      "15 58\n",
      "16 59\n",
      "17 60\n",
      "18 61\n",
      "19 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating x_d:   0%|          | 0/140 [00:00<?, ?it/s]C:\\Users\\JackeyTY\\AppData\\Local\\Temp\\ipykernel_153884\\3033579522.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "Generating x_d: 100%|██████████| 140/140 [00:00<00:00, 472.03it/s]\n",
      "Processing batches: 100%|██████████| 35/35 [00:04<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Profiling...\\n\")\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "with profile(activities = activities, profile_memory = True, record_shapes = True, with_stack = True, with_modules = True, with_flops = True) as prof:\n",
    "    with record_function(\"full_model_inference\"):\n",
    "        all_frames = process_motion_batch(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::cudnn_convolution         3.64%     180.944ms         3.64%     180.944ms      57.443us        1.560s        31.37%        1.560s     495.187us           0 b           0 b      91.15 Gb      91.15 Gb          3150            --  \n",
      "            full_model_inference        32.36%        1.609s       100.00%        4.973s        4.973s        1.219s        24.52%        4.973s        4.973s           0 b    -245.17 Mb           0 b    -295.89 Gb             1            --  \n",
      "                     aten::copy_        16.98%     844.409ms        16.98%     844.409ms      81.633us     250.858ms         5.04%     250.858ms      24.252us           0 b           0 b           0 b           0 b         10344            --  \n",
      "                  aten::_to_copy         7.10%     352.933ms        24.23%        1.205s     127.986us     195.923ms         3.94%     481.983ms      51.193us     210.06 Mb       9.56 Kb      17.81 Gb       1.05 Gb          9415            --  \n",
      "                        aten::to        10.67%     530.706ms        34.90%        1.736s     181.653us     181.669ms         3.65%     663.652ms      69.456us     210.06 Mb           0 b      17.81 Gb           0 b          9555            --  \n",
      "                    aten::conv2d         3.98%     198.151ms        36.79%        1.830s     339.458us     139.728ms         2.81%        3.106s     576.239us           0 b           0 b     139.39 Gb      -1.77 Gb          5390  252752460513.280  \n",
      "                      aten::add_         0.69%      34.244ms         0.69%      34.244ms      11.118us     132.154ms         2.66%     132.154ms      42.907us           0 b           0 b           0 b           0 b          3080            --  \n",
      "                       aten::add         0.45%      22.396ms         0.45%      22.396ms      12.073us     121.676ms         2.45%     121.676ms      65.594us           0 b           0 b      51.37 Gb      51.37 Gb          1855  27002160.360  \n",
      "                       aten::mul         0.37%      18.360ms         0.37%      18.360ms      11.154us      87.945ms         1.77%      87.945ms      53.430us           0 b           0 b      25.87 Gb      25.87 Gb          1646  12881771.841  \n",
      "         aten::native_batch_norm         1.37%      68.211ms         1.95%      97.204ms     154.292us      83.683ms         1.68%     123.489ms     196.014us           0 b           0 b      21.88 Gb     435.00 Kb           630            --  \n",
      "             aten::empty_strided         0.45%      22.444ms         0.45%      22.444ms       2.238us      68.043ms         1.37%      68.043ms       6.784us     210.05 Mb     210.05 Mb      38.40 Gb      38.40 Gb         10030            --  \n",
      "                   aten::reshape         2.20%     109.575ms         2.33%     115.972ms      17.163us      48.886ms         0.98%      79.386ms      11.749us           0 b           0 b           0 b           0 b          6757            --  \n",
      "                     aten::empty         0.19%       9.273ms         0.19%       9.273ms       1.507us      48.811ms         0.98%      48.811ms       7.934us      28.00 Mb      28.00 Mb      16.24 Gb      16.24 Gb          6152            --  \n",
      "                       aten::cat         0.50%      24.731ms         0.85%      42.113ms      52.185us      44.686ms         0.90%      63.091ms      78.180us           0 b           0 b      12.75 Gb      12.75 Gb           807            --  \n",
      "              aten::_convolution         3.50%     173.888ms         8.91%     443.146ms     140.681us      44.127ms         0.89%        1.750s     555.639us           0 b           0 b      74.20 Gb     -16.95 Gb          3150            --  \n",
      "        aten::upsample_nearest2d         0.47%      23.567ms         0.60%      29.613ms      42.304us      42.630ms         0.86%      52.433ms      74.904us           0 b           0 b      26.59 Gb      26.59 Gb           700            --  \n",
      "                    aten::repeat         1.32%      65.781ms         2.63%     130.641ms     287.123us      41.004ms         0.82%     132.968ms     292.237us           0 b           0 b       5.99 Gb      44.75 Mb           455            --  \n",
      "                      aten::view         0.22%      10.745ms         0.22%      10.745ms       1.101us      40.804ms         0.82%      40.804ms       4.181us           0 b           0 b           0 b           0 b          9759            --  \n",
      "               aten::convolution         1.25%      62.286ms        10.16%     505.432ms     160.455us      37.249ms         0.75%        1.788s     567.464us           0 b           0 b      74.20 Gb           0 b          3150            --  \n",
      "                       aten::dot         0.97%      48.389ms         2.40%     119.292ms      94.676us      35.448ms         0.71%     106.074ms      84.186us           0 b           0 b       1.05 Mb    -548.00 Kb          1260            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.973s\n",
      "Self CUDA time total: 4.973s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_by_keyword = 'self_cuda_time_total'\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "            full_model_inference        32.36%        1.609s       100.00%        4.973s        4.973s        1.219s        24.52%        4.973s        4.973s           0 b    -245.17 Mb           0 b    -295.89 Gb             1            --  \n",
      "                     aten::copy_        16.98%     844.409ms        16.98%     844.409ms      81.633us     250.858ms         5.04%     250.858ms      24.252us           0 b           0 b           0 b           0 b         10344            --  \n",
      "                        aten::to        10.67%     530.706ms        34.90%        1.736s     181.653us     181.669ms         3.65%     663.652ms      69.456us     210.06 Mb           0 b      17.81 Gb           0 b          9555            --  \n",
      "                  aten::_to_copy         7.10%     352.933ms        24.23%        1.205s     127.986us     195.923ms         3.94%     481.983ms      51.193us     210.06 Mb       9.56 Kb      17.81 Gb       1.05 Gb          9415            --  \n",
      "                    aten::conv2d         3.98%     198.151ms        36.79%        1.830s     339.458us     139.728ms         2.81%        3.106s     576.239us           0 b           0 b     139.39 Gb      -1.77 Gb          5390  252752460513.280  \n",
      "         aten::cudnn_convolution         3.64%     180.944ms         3.64%     180.944ms      57.443us        1.560s        31.37%        1.560s     495.187us           0 b           0 b      91.15 Gb      91.15 Gb          3150            --  \n",
      "              aten::_convolution         3.50%     173.888ms         8.91%     443.146ms     140.681us      44.127ms         0.89%        1.750s     555.639us           0 b           0 b      74.20 Gb     -16.95 Gb          3150            --  \n",
      "                   aten::reshape         2.20%     109.575ms         2.33%     115.972ms      17.163us      48.886ms         0.98%      79.386ms      11.749us           0 b           0 b           0 b           0 b          6757            --  \n",
      "         aten::native_batch_norm         1.37%      68.211ms         1.95%      97.204ms     154.292us      83.683ms         1.68%     123.489ms     196.014us           0 b           0 b      21.88 Gb     435.00 Kb           630            --  \n",
      "                    aten::repeat         1.32%      65.781ms         2.63%     130.641ms     287.123us      41.004ms         0.82%     132.968ms     292.237us           0 b           0 b       5.99 Gb      44.75 Mb           455            --  \n",
      "               aten::convolution         1.25%      62.286ms        10.16%     505.432ms     160.455us      37.249ms         0.75%        1.788s     567.464us           0 b           0 b      74.20 Gb           0 b          3150            --  \n",
      "                        aten::mv         1.14%      56.795ms         4.10%     203.765ms     161.718us      26.505ms         0.53%     158.929ms     126.134us           0 b           0 b     177.63 Mb      -1.85 Gb          1260            --  \n",
      "                       aten::dot         0.97%      48.389ms         2.40%     119.292ms      94.676us      35.448ms         0.71%     106.074ms      84.186us           0 b           0 b       1.05 Mb    -548.00 Kb          1260            --  \n",
      "          aten::cudnn_batch_norm         0.84%      41.785ms         1.05%      52.266ms     114.870us      23.637ms         0.48%      47.283ms     103.919us           0 b           0 b       5.98 Gb           0 b           455            --  \n",
      "                    aten::matmul         0.73%      36.223ms         1.46%      72.425ms     172.440us      24.988ms         0.50%      76.039ms     181.045us           0 b           0 b     210.00 Kb           0 b           420            --  \n",
      "                      aten::add_         0.69%      34.244ms         0.69%      34.244ms      11.118us     132.154ms         2.66%     132.154ms      42.907us           0 b           0 b           0 b           0 b          3080            --  \n",
      "                    aten::conv3d         0.68%      34.045ms         5.66%     281.350ms     309.176us      28.337ms         0.57%        1.147s       1.261ms           0 b           0 b      16.63 Gb      -3.34 Gb           910            --  \n",
      "                    aten::unfold         0.64%      32.033ms         0.65%      32.337ms      17.768us      30.567ms         0.61%      41.513ms      22.809us           0 b           0 b           0 b           0 b          1820            --  \n",
      "                    aten::expand         0.60%      29.826ms         0.61%      30.150ms      17.209us      32.279ms         0.65%      41.937ms      23.937us           0 b           0 b           0 b           0 b          1752            --  \n",
      "             aten::instance_norm         0.58%      28.781ms         3.19%     158.575ms     251.706us      10.832ms         0.22%     158.478ms     251.552us           0 b           0 b      21.88 Gb      -1.30 Mb           630            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.973s\n",
      "Self CUDA time total: 4.973s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_by_keyword = 'self_cpu_time_total'\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate motion feature shape: torch.Size([16, 65, 20])\n",
      "previous motion feature shape: torch.Size([1, 10, 20])\n",
      "f_s feature shape: torch.Size([1, 32, 16, 64, 64])\n",
      "x_s feature shape: torch.Size([1, 21, 3])\n"
     ]
    }
   ],
   "source": [
    "# 40s audio\n",
    "print(f\"generate motion feature shape: {generated_motion.shape}\")\n",
    "print(f\"previous motion feature shape: {motion_prev.shape}\")\n",
    "print(f\"f_s feature shape: {f_s.shape}\")\n",
    "print(f\"x_s feature shape: {x_s.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate motion feature shape: torch.Size([2, 65, 20])\n",
      "previous motion feature shape: torch.Size([1, 10, 20])\n",
      "f_s feature shape: torch.Size([1, 32, 16, 64, 64])\n",
      "x_s feature shape: torch.Size([1, 21, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3s audio\n",
    "print(f\"generate motion feature shape: {generated_motion.shape}\")\n",
    "print(f\"previous motion feature shape: {motion_prev.shape}\")\n",
    "print(f\"f_s feature shape: {f_s.shape}\")\n",
    "print(f\"x_s feature shape: {x_s.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with torch parallelized matrix operations\n",
    "\n",
    "def process_motion_batch2(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    frames = []\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        i1 = datetime.now()\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "        i2 = datetime.now()\n",
    "        out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "        i3 = datetime.now()\n",
    "        # Convert to numpy array\n",
    "        batch_frames = (out['out'].permute(0, 2, 3, 1).cpu().numpy() * 255).astype(np.uint8)\n",
    "        frames.extend(list(batch_frames))\n",
    "        i4 = datetime.now()\n",
    "        print(f\"{i4 - i1}: {i2 - i1} / {i3 - i2} / {i4 - i3}\")\n",
    "        t1 += (i3 - i2).total_seconds()\n",
    "        t2 += (i4 - i3).total_seconds()\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {end_time - middle_time}s\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "    print(f\"{t1} {t2}\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 2/35 [00:00<00:03, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.093062: 0:00:00 / 0:00:00.017556 / 0:00:00.075506\n",
      "0:00:00.097200: 0:00:00 / 0:00:00.015651 / 0:00:00.081549\n",
      "0:00:00.095585: 0:00:00 / 0:00:00.016017 / 0:00:00.079568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 4/35 [00:00<00:02, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.093537: 0:00:00 / 0:00:00.018015 / 0:00:00.075522\n",
      "0:00:00.090629: 0:00:00 / 0:00:00.019112 / 0:00:00.071517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 6/35 [00:00<00:02, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.090044: 0:00:00 / 0:00:00.016018 / 0:00:00.074026\n",
      "0:00:00.090803: 0:00:00 / 0:00:00.015237 / 0:00:00.075566\n",
      "0:00:00.097346: 0:00:00 / 0:00:00.015035 / 0:00:00.082311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 8/35 [00:00<00:02, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.097585: 0:00:00 / 0:00:00.018508 / 0:00:00.079077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 10/35 [00:00<00:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.092244: 0:00:00 / 0:00:00.017505 / 0:00:00.074739\n",
      "0:00:00.090588: 0:00:00 / 0:00:00.016064 / 0:00:00.074524\n",
      "0:00:00.096046: 0:00:00 / 0:00:00.015570 / 0:00:00.080476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 14/35 [00:01<00:01, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0:00:00.090562: 0:00:00 / 0:00:00.015505 / 0:00:00.075057\n",
      "0:00:00.091057: 0:00:00 / 0:00:00.016026 / 0:00:00.075031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 16/35 [00:01<00:01, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.093098: 0:00:00 / 0:00:00.016506 / 0:00:00.076592\n",
      "0:00:00.091634: 0:00:00 / 0:00:00.016509 / 0:00:00.075125\n",
      "0:00:00.090044: 0:00:00 / 0:00:00.016013 / 0:00:00.074031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 20/35 [00:01<00:01, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.093614: 0:00:00 / 0:00:00.015506 / 0:00:00.078108\n",
      "0:00:00.098101: 0:00:00 / 0:00:00.017517 / 0:00:00.080584\n",
      "0:00:00.092676: 0:00:00 / 0:00:00.017016 / 0:00:00.075660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 22/35 [00:02<00:01, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.092567: 0:00:00 / 0:00:00.018016 / 0:00:00.074551\n",
      "0:00:00.092537: 0:00:00 / 0:00:00.016510 / 0:00:00.076027\n",
      "0:00:00.093036: 0:00:00 / 0:00:00.015500 / 0:00:00.077536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 26/35 [00:02<00:00, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.097230: 0:00:00 / 0:00:00.017511 / 0:00:00.079719\n",
      "0:00:00.092582: 0:00:00 / 0:00:00.015047 / 0:00:00.077535\n",
      "0:00:00.091598: 0:00:00 / 0:00:00.018511 / 0:00:00.073087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 28/35 [00:02<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.094096: 0:00:00 / 0:00:00.017012 / 0:00:00.077084\n",
      "0:00:00.098565: 0:00:00 / 0:00:00.017043 / 0:00:00.081522\n",
      "0:00:00.090093: 0:00:00 / 0:00:00.015056 / 0:00:00.075037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 30/35 [00:02<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.089565: 0:00:00 / 0:00:00.015539 / 0:00:00.074026\n",
      "0:00:00.093544: 0:00:00 / 0:00:00.016505 / 0:00:00.077039\n",
      "0:00:00.089670: 0:00:00.001000 / 0:00:00.015082 / 0:00:00.073588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [00:03<00:00, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.094557: 0:00:00 / 0:00:00.015506 / 0:00:00.079051\n",
      "0:00:00.091057: 0:00:00 / 0:00:00.015506 / 0:00:00.075551\n",
      "0:00:00.094598: 0:00:00 / 0:00:00.014510 / 0:00:00.080088\n",
      "\n",
      "time to prep x_d 0:00:00.002510s\n",
      "time to warp and decode 0:00:03.270764s\n",
      "total generation time 0:00:03.273274\n",
      "0.5737400000000001 2.6860100000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch2(generated_motion, motion_prev, f_s, x_s, warp_decode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with fast pinned memeory transfer\n",
    "\n",
    "def process_motion_batch3(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        i1 = datetime.now()\n",
    "        # Step 1 calculate starting and ending index for current batch\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "        i2 = datetime.now()\n",
    "        # Step 2 process current batch through the warp_decode_func\n",
    "        out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "        i3 = datetime.now()\n",
    "        # Step 3 convert to numpy array and store it in output\n",
    "        output_buffer[start_idx:end_idx].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8), non_blocking = False)\n",
    "        i4 = datetime.now()\n",
    "        print(f\"{i4 - i1}: {i2 - i1} / {i3 - i2} / {i4 - i3}\")\n",
    "        t1 += (i3 - i2).total_seconds()\n",
    "        t2 += (i4 - i3).total_seconds()\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "    print(f\"{t1} {t2}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 2/35 [00:00<00:02, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.069265: 0:00:00 / 0:00:00.016504 / 0:00:00.052761\n",
      "0:00:00.068031: 0:00:00 / 0:00:00.019002 / 0:00:00.049029\n",
      "0:00:00.063028: 0:00:00 / 0:00:00.016004 / 0:00:00.047024\n",
      "0:00:00.064533: 0:00:00 / 0:00:00.016509 / 0:00:00.048024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 6/35 [00:00<00:01, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0:00:00.070521: 0:00:00 / 0:00:00.015001 / 0:00:00.055520\n",
      "0:00:00.064419: 0:00:00 / 0:00:00.017029 / 0:00:00.047390\n",
      "0:00:00.063541: 0:00:00 / 0:00:00.017010 / 0:00:00.046531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 10/35 [00:00<00:01, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064527: 0:00:00 / 0:00:00.016506 / 0:00:00.048021\n",
      "0:00:00.064531: 0:00:00 / 0:00:00.017013 / 0:00:00.047518\n",
      "0:00:00.063525: 0:00:00 / 0:00:00.016508 / 0:00:00.047017\n",
      "0:00:00.063532: 0:00:00 / 0:00:00.017006 / 0:00:00.046526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 14/35 [00:00<00:01, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.063593: 0:00:00 / 0:00:00.019007 / 0:00:00.044586\n",
      "0:00:00.065529: 0:00:00 / 0:00:00.018509 / 0:00:00.047020\n",
      "0:00:00.064102: 0:00:00 / 0:00:00.015508 / 0:00:00.048594\n",
      "0:00:00.064027: 0:00:00 / 0:00:00.017002 / 0:00:00.047025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 18/35 [00:01<00:01, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.065039: 0:00:00 / 0:00:00.018506 / 0:00:00.046533\n",
      "0:00:00.064585: 0:00:00 / 0:00:00.017537 / 0:00:00.047048\n",
      "0:00:00.064524: 0:00:00 / 0:00:00.016511 / 0:00:00.048013\n",
      "0:00:00.063656: 0:00:00 / 0:00:00.015108 / 0:00:00.048548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 22/35 [00:01<00:00, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064527: 0:00:00 / 0:00:00.016512 / 0:00:00.048015\n",
      "0:00:00.065028: 0:00:00 / 0:00:00.018513 / 0:00:00.046515\n",
      "0:00:00.064019: 0:00:00 / 0:00:00.016506 / 0:00:00.047513\n",
      "0:00:00.063553: 0:00:00 / 0:00:00.015035 / 0:00:00.048518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 26/35 [00:01<00:00, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064565: 0:00:00 / 0:00:00.018538 / 0:00:00.046027\n",
      "0:00:00.063547: 0:00:00 / 0:00:00.017003 / 0:00:00.046544\n",
      "0:00:00.064525: 0:00:00 / 0:00:00.017505 / 0:00:00.047020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 30/35 [00:01<00:00, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064029: 0:00:00 / 0:00:00.015509 / 0:00:00.048520\n",
      "0:00:00.063517: 0:00:00 / 0:00:00.016003 / 0:00:00.047514\n",
      "0:00:00.064523: 0:00:00 / 0:00:00.016001 / 0:00:00.048522\n",
      "0:00:00.063530: 0:00:00 / 0:00:00.017007 / 0:00:00.046523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████▏| 32/35 [00:02<00:00, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.065049: 0:00:00 / 0:00:00.017021 / 0:00:00.048028\n",
      "0:00:00.064084: 0:00:00 / 0:00:00.015003 / 0:00:00.049081\n",
      "0:00:00.065027: 0:00:00.001000 / 0:00:00.015011 / 0:00:00.049016\n",
      "0:00:00.064041: 0:00:00 / 0:00:00.017028 / 0:00:00.047013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [00:02<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064033: 0:00:00 / 0:00:00.017516 / 0:00:00.046517\n",
      "\n",
      "time to prep x_d 0:00:00.003030s\n",
      "time to warp and decode 0:00:02.278204s\n",
      "time to transfer pinned to cpu 0:00:00\n",
      "total generation time 0:00:02.281234\n",
      "0.587491 1.6736139999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch3(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with multiple streams attemp 1\n",
    "\n",
    "def process_motion_batch4(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "    streams = [torch.cuda.Stream(), torch.cuda.Stream()]\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        i1 = datetime.now()\n",
    "        # Step 1 calculate starting and ending index for current batch\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "\n",
    "        with torch.cuda.stream(streams[i % 2]):\n",
    "            i2 = datetime.now()\n",
    "            # Step 2 process current batch through the warp_decode_func\n",
    "            out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "            i3 = datetime.now()\n",
    "            # Step 3 write to output pinned memory buffer\n",
    "            output_buffer[start_idx:end_idx].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8), non_blocking = True)\n",
    "        i4 = datetime.now()\n",
    "        print(f\"{i4 - i1}: {i2 - i1} / {i3 - i2} / {i4 - i3}\")\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "    del streams\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 2/35 [00:00<00:01, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.036010: 0:00:00 / 0:00:00.036010 / 0:00:00\n",
      "0:00:00.075439: 0:00:00 / 0:00:00.075439 / 0:00:00\n",
      "0:00:00.064029: 0:00:00 / 0:00:00.063026 / 0:00:00.001003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 6/35 [00:00<00:01, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.066563: 0:00:00 / 0:00:00.066563 / 0:00:00\n",
      "0:00:00.061030: 0:00:00 / 0:00:00.061030 / 0:00:00\n",
      "0:00:00.062120: 0:00:00 / 0:00:00.062120 / 0:00:00\n",
      "0:00:00.062967: 0:00:00 / 0:00:00.061967 / 0:00:00.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 10/35 [00:00<00:01, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.062640: 0:00:00 / 0:00:00.061640 / 0:00:00.001000\n",
      "0:00:00.062044: 0:00:00 / 0:00:00.061042 / 0:00:00.001002\n",
      "0:00:00.062749: 0:00:00 / 0:00:00.061748 / 0:00:00.001001\n",
      "0:00:00.061031: 0:00:00 / 0:00:00.061031 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 14/35 [00:00<00:01, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.063038: 0:00:00.001000 / 0:00:00.062038 / 0:00:00\n",
      "0:00:00.064091: 0:00:00 / 0:00:00.064091 / 0:00:00\n",
      "0:00:00.062798: 0:00:00 / 0:00:00.062798 / 0:00:00\n",
      "0:00:00.061555: 0:00:00 / 0:00:00.061555 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 18/35 [00:01<00:01, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.062080: 0:00:00 / 0:00:00.062080 / 0:00:00\n",
      "0:00:00.062520: 0:00:00 / 0:00:00.062520 / 0:00:00\n",
      "0:00:00.063876: 0:00:00 / 0:00:00.063876 / 0:00:00\n",
      "0:00:00.061036: 0:00:00 / 0:00:00.061036 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 22/35 [00:01<00:00, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.063087: 0:00:00 / 0:00:00.063087 / 0:00:00\n",
      "0:00:00.060024: 0:00:00 / 0:00:00.060024 / 0:00:00\n",
      "0:00:00.062519: 0:00:00 / 0:00:00.062519 / 0:00:00\n",
      "0:00:00.061519: 0:00:00 / 0:00:00.061519 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 26/35 [00:01<00:00, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.062760: 0:00:00 / 0:00:00.062760 / 0:00:00\n",
      "0:00:00.062050: 0:00:00 / 0:00:00.061050 / 0:00:00.001000\n",
      "0:00:00.062519: 0:00:00 / 0:00:00.062519 / 0:00:00\n",
      "0:00:00.060018: 0:00:00 / 0:00:00.060018 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 30/35 [00:01<00:00, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.064603: 0:00:00 / 0:00:00.064603 / 0:00:00\n",
      "0:00:00.061019: 0:00:00 / 0:00:00.061019 / 0:00:00\n",
      "0:00:00.061523: 0:00:00.001000 / 0:00:00.060523 / 0:00:00\n",
      "0:00:00.062349: 0:00:00 / 0:00:00.062349 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 34/35 [00:02<00:00, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.062470: 0:00:00 / 0:00:00.062470 / 0:00:00\n",
      "0:00:00.061523: 0:00:00 / 0:00:00.060523 / 0:00:00.001000\n",
      "0:00:00.064560: 0:00:00 / 0:00:00.064560 / 0:00:00\n",
      "0:00:00.062598: 0:00:00 / 0:00:00.062598 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [00:02<00:00, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time to prep x_d 0:00:00.006011s\n",
      "time to warp and decode 0:00:02.231290s\n",
      "time to transfer pinned to cpu 0:00:00.040614\n",
      "total generation time 0:00:02.277915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch4(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with multiple streams attemp 2\n",
    "\n",
    "def process_motion_batch5(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "    compute_stream = torch.cuda.Stream()\n",
    "    copy_stream = torch.cuda.Stream()\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "\n",
    "        # Step 1 calculate starting and ending index for current batch\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "\n",
    "        with torch.cuda.stream(compute_stream):\n",
    "            # Step 2 process current batch through the warp_decode_func which is basically a MLP + decoder\n",
    "            out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "\n",
    "        with torch.cuda.stream(copy_stream):\n",
    "            copy_stream.wait_stream(compute_stream)\n",
    "            # Step 3 convert to numpy array and store it in output\n",
    "            output_buffer[start_idx:end_idx].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8), non_blocking = True)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "    del compute_stream\n",
    "    del copy_stream\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [00:02<00:00, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time to prep x_d 0:00:00.004016s\n",
      "time to warp and decode 0:00:02.262946s\n",
      "time to transfer pinned to cpu 0:00:00.008503\n",
      "total generation time 0:00:02.275465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch5(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with multiple streams attemp 3\n",
    "\n",
    "def process_motion_batch6(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 4\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "    compute_stream = torch.cuda.Stream()\n",
    "    copy_stream = torch.cuda.Stream()\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    with torch.cuda.stream(compute_stream):\n",
    "        for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "\n",
    "            # Step 1 calculate starting and ending index for current batch\n",
    "            start_idx = i * inference_batch_size\n",
    "            end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "\n",
    "            # Step 2 process current batch through the warp_decode_func which is basically a MLP + decoder\n",
    "            out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "\n",
    "            with torch.cuda.stream(copy_stream):\n",
    "                # Step 3 convert to numpy array and store it in output\n",
    "                output_buffer[start_idx:end_idx].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8), non_blocking = True)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "    del compute_stream\n",
    "    del copy_stream\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 35/35 [00:02<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time to prep x_d 0:00:00.003030s\n",
      "time to warp and decode 0:00:02.267006s\n",
      "time to transfer pinned to cpu 0:00:00.007508\n",
      "total generation time 0:00:02.277544\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch6(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized warp and decoder model\n",
    "\n",
    "feature_3d_example = torch.randn(1, 32, 16, 64, 64, device = device)\n",
    "kp_source_example = torch.randn(1, 21, 3, device = device)\n",
    "kp_driving_example = torch.randn(1, 21, 3, device = device)\n",
    "ret_out_example = torch.randn(1, 256, 256, 64, device = device)\n",
    "\n",
    "traced_warping_module = torch.jit.trace(warping_module, (feature_3d_example, kp_source_example, kp_driving_example), strict = False)\n",
    "traced_spade_generator = torch.jit.trace(spade_generator, ret_out_example)\n",
    "\n",
    "def warp_decode_optimized(feature_3d: torch.Tensor, kp_source: torch.Tensor, kp_driving: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\" get the image after the warping of the implicit keypoints\n",
    "    feature_3d: Bx32x16x64x64, feature volume\n",
    "    kp_source: BxNx3\n",
    "    kp_driving: BxNx3\n",
    "    \"\"\"\n",
    "    # The line 18 in Algorithm 1: D(W(f_s; x_s, x′_d,i)）\n",
    "    with torch.no_grad(), torch.autocast(device_type = 'cuda', dtype = torch.float16, enabled = inference_cfg.flag_use_half_precision):\n",
    "\n",
    "        # torch.compiler.cudagraph_mark_step_begin()\n",
    "        # get decoder input\n",
    "        ret_dct = traced_warping_module(feature_3d, kp_source = kp_source, kp_driving = kp_driving)\n",
    "\n",
    "        # decode\n",
    "        ret_dct['out'] = traced_spade_generator(feature = ret_dct['out'])\n",
    "\n",
    "    return ret_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames Optimized with TorchScript computation graph\n",
    "\n",
    "def process_motion_batch7(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "    f_s_batch = f_s.expand(x_d_batch.shape[0], -1, -1, -1, -1)\n",
    "    x_s_batch = x_s.expand(x_d_batch.shape[0], -1, -1)\n",
    "\n",
    "    inference_batch_size = 1\n",
    "    num_batches = (x_d_batch.shape[0] + inference_batch_size - 1) // inference_batch_size\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        i1 = datetime.now()\n",
    "        # Step 1 calculate starting and ending index for current batch\n",
    "        start_idx = i * inference_batch_size\n",
    "        end_idx = min((i + 1) * inference_batch_size, x_d_batch.shape[0])\n",
    "        i2 = datetime.now()\n",
    "        # Step 2 process current batch through the warp_decode_func which is basically a MLP + decoder\n",
    "        out = warp_decode_func(f_s_batch[start_idx:end_idx], x_s_batch[start_idx:end_idx], x_d_batch[start_idx:end_idx])\n",
    "        i3 = datetime.now()\n",
    "        # Step 3 convert to numpy array and store it in output\n",
    "        output_buffer[start_idx:end_idx].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8), non_blocking = True)\n",
    "        i4 = datetime.now()\n",
    "        print(f\"{i4 - i1}: {i2 - i1} / {i3 - i2} / {i4 - i3}\")\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 6/140 [00:00<00:02, 50.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.013561: 0:00:00 / 0:00:00.013561 / 0:00:00\n",
      "0:00:00.019985: 0:00:00 / 0:00:00.019985 / 0:00:00\n",
      "0:00:00.023509: 0:00:00 / 0:00:00.022509 / 0:00:00.001000\n",
      "0:00:00.019511: 0:00:00 / 0:00:00.019511 / 0:00:00\n",
      "0:00:00.020502: 0:00:00 / 0:00:00.020502 / 0:00:00\n",
      "0:00:00.021507: 0:00:00 / 0:00:00.021507 / 0:00:00\n",
      "0:00:00.023010: 0:00:00 / 0:00:00.022010 / 0:00:00.001000\n",
      "0:00:00.021507: 0:00:00 / 0:00:00.021507 / 0:00:00\n",
      "0:00:00.023509: 0:00:00 / 0:00:00.023509 / 0:00:00\n",
      "0:00:00.018505: 0:00:00 / 0:00:00.018505 / 0:00:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 17/140 [00:00<00:02, 48.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0:00:00.021522: 0:00:00 / 0:00:00.021522 / 0:00:00\n",
      "0:00:00.021002: 0:00:00 / 0:00:00.021002 / 0:00:00\n",
      "0:00:00.022504: 0:00:00 / 0:00:00.022504 / 0:00:00\n",
      "0:00:00.019021: 0:00:00 / 0:00:00.019021 / 0:00:00\n",
      "0:00:00.020001: 0:00:00 / 0:00:00.020001 / 0:00:00\n",
      "0:00:00.020018: 0:00:00 / 0:00:00.020018 / 0:00:00\n",
      "0:00:00.021011: 0:00:00 / 0:00:00.021011 / 0:00:00\n",
      "0:00:00.020003: 0:00:00 / 0:00:00.020003 / 0:00:00\n",
      "0:00:00.020529: 0:00:00 / 0:00:00.019529 / 0:00:00.001000\n",
      "0:00:00.019003: 0:00:00 / 0:00:00.019003 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 29/140 [00:00<00:02, 48.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.023520: 0:00:00 / 0:00:00.023520 / 0:00:00\n",
      "0:00:00.014506: 0:00:00 / 0:00:00.014506 / 0:00:00\n",
      "0:00:00.026022: 0:00:00 / 0:00:00.026022 / 0:00:00\n",
      "0:00:00.018002: 0:00:00 / 0:00:00.018002 / 0:00:00\n",
      "0:00:00.019508: 0:00:00 / 0:00:00.019508 / 0:00:00\n",
      "0:00:00.020505: 0:00:00 / 0:00:00.020505 / 0:00:00\n",
      "0:00:00.019509: 0:00:00 / 0:00:00.018509 / 0:00:00.001000\n",
      "0:00:00.019508: 0:00:00 / 0:00:00.019508 / 0:00:00\n",
      "0:00:00.021512: 0:00:00 / 0:00:00.021512 / 0:00:00\n",
      "0:00:00.019509: 0:00:00 / 0:00:00.018509 / 0:00:00.001000\n",
      "0:00:00.018011: 0:00:00 / 0:00:00.018011 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 40/140 [00:00<00:02, 49.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020001: 0:00:00 / 0:00:00.020001 / 0:00:00\n",
      "0:00:00.020507: 0:00:00 / 0:00:00.020507 / 0:00:00\n",
      "0:00:00.019017: 0:00:00 / 0:00:00.018010 / 0:00:00.001007\n",
      "0:00:00.022999: 0:00:00 / 0:00:00.022999 / 0:00:00\n",
      "0:00:00.017525: 0:00:00 / 0:00:00.017525 / 0:00:00\n",
      "0:00:00.021513: 0:00:00 / 0:00:00.021513 / 0:00:00\n",
      "0:00:00.022001: 0:00:00 / 0:00:00.022001 / 0:00:00\n",
      "0:00:00.018017: 0:00:00 / 0:00:00.018017 / 0:00:00\n",
      "0:00:00.021002: 0:00:00 / 0:00:00.021002 / 0:00:00\n",
      "0:00:00.019016: 0:00:00 / 0:00:00.019016 / 0:00:00\n",
      "0:00:00.019507: 0:00:00 / 0:00:00.019507 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▋      | 51/140 [00:01<00:01, 49.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020006: 0:00:00 / 0:00:00.020006 / 0:00:00\n",
      "0:00:00.022511: 0:00:00.000999 / 0:00:00.021512 / 0:00:00\n",
      "0:00:00.020008: 0:00:00 / 0:00:00.020008 / 0:00:00\n",
      "0:00:00.021016: 0:00:00 / 0:00:00.021016 / 0:00:00\n",
      "0:00:00.017552: 0:00:00 / 0:00:00.016554 / 0:00:00.000998\n",
      "0:00:00.020023: 0:00:00 / 0:00:00.020023 / 0:00:00\n",
      "0:00:00.018000: 0:00:00 / 0:00:00.018000 / 0:00:00\n",
      "0:00:00.019507: 0:00:00 / 0:00:00.019507 / 0:00:00\n",
      "0:00:00.019512: 0:00:00 / 0:00:00.019512 / 0:00:00\n",
      "0:00:00.024004: 0:00:00 / 0:00:00.024004 / 0:00:00\n",
      "0:00:00.017027: 0:00:00 / 0:00:00.017027 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 62/140 [00:01<00:01, 49.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020019: 0:00:00 / 0:00:00.020019 / 0:00:00\n",
      "0:00:00.024503: 0:00:00 / 0:00:00.024503 / 0:00:00\n",
      "0:00:00.017008: 0:00:00 / 0:00:00.017008 / 0:00:00\n",
      "0:00:00.021108: 0:00:00 / 0:00:00.021108 / 0:00:00\n",
      "0:00:00.020501: 0:00:00 / 0:00:00.020501 / 0:00:00\n",
      "0:00:00.017506: 0:00:00 / 0:00:00.017506 / 0:00:00\n",
      "0:00:00.019001: 0:00:00 / 0:00:00.019001 / 0:00:00\n",
      "0:00:00.019507: 0:00:00 / 0:00:00.019507 / 0:00:00\n",
      "0:00:00.023506: 0:00:00 / 0:00:00.023506 / 0:00:00\n",
      "0:00:00.019002: 0:00:00 / 0:00:00.019002 / 0:00:00\n",
      "0:00:00.019509: 0:00:00 / 0:00:00.019509 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 74/140 [00:01<00:01, 49.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.019505: 0:00:00 / 0:00:00.019505 / 0:00:00\n",
      "0:00:00.020010: 0:00:00 / 0:00:00.020010 / 0:00:00\n",
      "0:00:00.020504: 0:00:00 / 0:00:00.020504 / 0:00:00\n",
      "0:00:00.020513: 0:00:00 / 0:00:00.020513 / 0:00:00\n",
      "0:00:00.019003: 0:00:00 / 0:00:00.019003 / 0:00:00\n",
      "0:00:00.019504: 0:00:00 / 0:00:00.018504 / 0:00:00.001000\n",
      "0:00:00.021516: 0:00:00 / 0:00:00.020518 / 0:00:00.000998\n",
      "0:00:00.018002: 0:00:00 / 0:00:00.018002 / 0:00:00\n",
      "0:00:00.020014: 0:00:00 / 0:00:00.020014 / 0:00:00\n",
      "0:00:00.021002: 0:00:00 / 0:00:00.021002 / 0:00:00\n",
      "0:00:00.021024: 0:00:00 / 0:00:00.021024 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 85/140 [00:01<00:01, 50.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.022506: 0:00:00 / 0:00:00.022506 / 0:00:00\n",
      "0:00:00.017000: 0:00:00 / 0:00:00.017000 / 0:00:00\n",
      "0:00:00.021009: 0:00:00 / 0:00:00.021009 / 0:00:00\n",
      "0:00:00.018508: 0:00:00 / 0:00:00.017508 / 0:00:00.001000\n",
      "0:00:00.022512: 0:00:00 / 0:00:00.022512 / 0:00:00\n",
      "0:00:00.021013: 0:00:00 / 0:00:00.021013 / 0:00:00\n",
      "0:00:00.017504: 0:00:00 / 0:00:00.016504 / 0:00:00.001000\n",
      "0:00:00.018507: 0:00:00 / 0:00:00.017507 / 0:00:00.001000\n",
      "0:00:00.020061: 0:00:00 / 0:00:00.020061 / 0:00:00\n",
      "0:00:00.018001: 0:00:00 / 0:00:00.018001 / 0:00:00\n",
      "0:00:00.022512: 0:00:00 / 0:00:00.022512 / 0:00:00\n",
      "0:00:00.017511: 0:00:00 / 0:00:00.017511 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 95/140 [00:01<00:00, 49.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020508: 0:00:00 / 0:00:00.020508 / 0:00:00\n",
      "0:00:00.022509: 0:00:00 / 0:00:00.022509 / 0:00:00\n",
      "0:00:00.017014: 0:00:00 / 0:00:00.016015 / 0:00:00.000999\n",
      "0:00:00.022004: 0:00:00 / 0:00:00.022004 / 0:00:00\n",
      "0:00:00.020507: 0:00:00 / 0:00:00.020507 / 0:00:00\n",
      "0:00:00.017528: 0:00:00 / 0:00:00.017528 / 0:00:00\n",
      "0:00:00.022006: 0:00:00 / 0:00:00.022006 / 0:00:00\n",
      "0:00:00.020515: 0:00:00 / 0:00:00.019515 / 0:00:00.001000\n",
      "0:00:00.019011: 0:00:00 / 0:00:00.019011 / 0:00:00\n",
      "0:00:00.021507: 0:00:00 / 0:00:00.021507 / 0:00:00\n",
      "0:00:00.021011: 0:00:00 / 0:00:00.021011 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 106/140 [00:02<00:00, 49.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.018095: 0:00:00 / 0:00:00.018095 / 0:00:00\n",
      "0:00:00.019011: 0:00:00 / 0:00:00.019011 / 0:00:00\n",
      "0:00:00.020511: 0:00:00 / 0:00:00.020511 / 0:00:00\n",
      "0:00:00.021004: 0:00:00 / 0:00:00.021004 / 0:00:00\n",
      "0:00:00.021554: 0:00:00 / 0:00:00.021554 / 0:00:00\n",
      "0:00:00.018508: 0:00:00 / 0:00:00.018508 / 0:00:00\n",
      "0:00:00.022515: 0:00:00 / 0:00:00.022515 / 0:00:00\n",
      "0:00:00.019563: 0:00:00 / 0:00:00.019563 / 0:00:00\n",
      "0:00:00.017502: 0:00:00 / 0:00:00.017502 / 0:00:00\n",
      "0:00:00.020507: 0:00:00 / 0:00:00.020507 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▎ | 117/140 [00:02<00:00, 49.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021508: 0:00:00 / 0:00:00.021508 / 0:00:00\n",
      "0:00:00.020516: 0:00:00 / 0:00:00.020516 / 0:00:00\n",
      "0:00:00.019002: 0:00:00 / 0:00:00.019002 / 0:00:00\n",
      "0:00:00.020504: 0:00:00 / 0:00:00.020504 / 0:00:00\n",
      "0:00:00.019011: 0:00:00 / 0:00:00.019011 / 0:00:00\n",
      "0:00:00.020001: 0:00:00 / 0:00:00.020001 / 0:00:00\n",
      "0:00:00.018010: 0:00:00 / 0:00:00.018010 / 0:00:00\n",
      "0:00:00.019503: 0:00:00 / 0:00:00.019503 / 0:00:00\n",
      "0:00:00.022509: 0:00:00 / 0:00:00.022509 / 0:00:00\n",
      "0:00:00.018546: 0:00:00 / 0:00:00.018546 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████▏| 128/140 [00:02<00:00, 49.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020001: 0:00:00 / 0:00:00.020001 / 0:00:00\n",
      "0:00:00.021013: 0:00:00 / 0:00:00.021013 / 0:00:00\n",
      "0:00:00.020012: 0:00:00 / 0:00:00.020012 / 0:00:00\n",
      "0:00:00.020004: 0:00:00 / 0:00:00.020004 / 0:00:00\n",
      "0:00:00.021014: 0:00:00 / 0:00:00.021014 / 0:00:00\n",
      "0:00:00.017507: 0:00:00 / 0:00:00.017507 / 0:00:00\n",
      "0:00:00.023015: 0:00:00 / 0:00:00.023015 / 0:00:00\n",
      "0:00:00.018507: 0:00:00 / 0:00:00.018507 / 0:00:00\n",
      "0:00:00.020508: 0:00:00 / 0:00:00.020508 / 0:00:00\n",
      "0:00:00.021506: 0:00:00 / 0:00:00.021506 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 134/140 [00:02<00:00, 49.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.017513: 0:00:00 / 0:00:00.017513 / 0:00:00\n",
      "0:00:00.019023: 0:00:00 / 0:00:00.019023 / 0:00:00\n",
      "0:00:00.020512: 0:00:00.001001 / 0:00:00.019511 / 0:00:00\n",
      "0:00:00.017514: 0:00:00 / 0:00:00.017514 / 0:00:00\n",
      "0:00:00.020502: 0:00:00 / 0:00:00.020502 / 0:00:00\n",
      "0:00:00.022512: 0:00:00 / 0:00:00.022512 / 0:00:00\n",
      "0:00:00.018541: 0:00:00 / 0:00:00.018541 / 0:00:00\n",
      "0:00:00.019000: 0:00:00 / 0:00:00.019000 / 0:00:00\n",
      "0:00:00.019505: 0:00:00 / 0:00:00.019505 / 0:00:00\n",
      "0:00:00.020012: 0:00:00 / 0:00:00.020012 / 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 140/140 [00:02<00:00, 49.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.023006: 0:00:00 / 0:00:00.023006 / 0:00:00\n",
      "0:00:00.018042: 0:00:00 / 0:00:00.018042 / 0:00:00\n",
      "\n",
      "time to prep x_d 0:00:00.003082s\n",
      "time to warp and decode 0:00:02.838216s\n",
      "time to transfer pinned to cpu 0:00:00\n",
      "total generation time 0:00:02.841298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch7(generated_motion, motion_prev, f_s, x_s, warp_decode_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frames sequentially (frame by frame)\n",
    "\n",
    "def process_motion_batch8(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func):\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    # pose = generated_motion[:, -5:]\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "    print(f\"generated motion shape {generated_motion.shape}\\n\")\n",
    "    print(f\"full motion shape {full_motion.shape}\\n\")\n",
    "\n",
    "    # t = torch.zeros((1, 3), dtype = torch.float32, device = device)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    print(f\"x_d shape {x_d_batch.shape}\\n\")\n",
    "\n",
    "    output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "\n",
    "    middle_time = datetime.now()\n",
    "\n",
    "    for i in tqdm(range(x_d_batch.shape[0]), desc=\"Processing batches\"):\n",
    "        i1 = datetime.now()\n",
    "        # Step 1 process current frame through the warp_decode_func\n",
    "        out = warp_decode_func(f_s, x_s, x_d_batch[i].unsqueeze(0))\n",
    "        i2 = datetime.now()\n",
    "        # Step 2 write to output pinned memory buffer\n",
    "        output_buffer[i].copy_(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8).squeeze(0), non_blocking = False)\n",
    "        i3 = datetime.now()\n",
    "        print(f\"{i3 - i1}: {i2 - i1} / {i3 - i2}\")\n",
    "\n",
    "    next_time = datetime.now()\n",
    "\n",
    "    frames = list(output_buffer.cpu().numpy())\n",
    "    del output_buffer\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    print(f\"\\ntime to prep x_d {middle_time - start_time}s\")\n",
    "    print(f\"time to warp and decode {next_time - middle_time}s\")\n",
    "    print(f\"time to transfer pinned to cpu {end_time - next_time}\")\n",
    "    print(f\"total generation time {end_time - start_time}\")\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated motion shape torch.Size([140, 20])\n",
      "\n",
      "full motion shape torch.Size([140, 63])\n",
      "\n",
      "x_d shape torch.Size([140, 21, 3])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 1/140 [00:00<00:15,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.113147: 0:00:00.112147 / 0:00:00.001000\n",
      "0:00:00.020004: 0:00:00.015009 / 0:00:00.004995\n",
      "0:00:00.022024: 0:00:00.016030 / 0:00:00.005994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 11/140 [00:00<00:03, 38.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020557: 0:00:00.015561 / 0:00:00.004996\n",
      "0:00:00.021091: 0:00:00.015090 / 0:00:00.006001\n",
      "0:00:00.021844: 0:00:00.014842 / 0:00:00.007002\n",
      "0:00:00.020509: 0:00:00.015511 / 0:00:00.004998\n",
      "0:00:00.021502: 0:00:00.018503 / 0:00:00.002999\n",
      "0:00:00.020016: 0:00:00.017010 / 0:00:00.003006\n",
      "0:00:00.020545: 0:00:00.016037 / 0:00:00.004508\n",
      "0:00:00.020001: 0:00:00.016001 / 0:00:00.004000\n",
      "0:00:00.020505: 0:00:00.015505 / 0:00:00.005000\n",
      "0:00:00.021012: 0:00:00.017011 / 0:00:00.004001\n",
      "0:00:00.019508: 0:00:00.016508 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 16/140 [00:00<00:02, 42.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020507: 0:00:00.017508 / 0:00:00.002999\n",
      "0:00:00.021016: 0:00:00.018017 / 0:00:00.002999\n",
      "0:00:00.020002: 0:00:00.017002 / 0:00:00.003000\n",
      "0:00:00.020621: 0:00:00.017621 / 0:00:00.003000\n",
      "0:00:00.020033: 0:00:00.017038 / 0:00:00.002995\n",
      "0:00:00.020503: 0:00:00.017503 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 21/140 [00:00<00:02, 44.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.019506: 0:00:00.014509 / 0:00:00.004997\n",
      "0:00:00.020528: 0:00:00.016003 / 0:00:00.004525\n",
      "0:00:00.020011: 0:00:00.017013 / 0:00:00.002998\n",
      "0:00:00.022539: 0:00:00.019540 / 0:00:00.002999\n",
      "0:00:00.020020: 0:00:00.017014 / 0:00:00.003006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▊        | 26/140 [00:00<00:02, 45.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021002: 0:00:00.018001 / 0:00:00.003001\n",
      "0:00:00.020027: 0:00:00.017029 / 0:00:00.002998\n",
      "0:00:00.021534: 0:00:00.018534 / 0:00:00.003000\n",
      "0:00:00.021515: 0:00:00.018516 / 0:00:00.002999\n",
      "0:00:00.020517: 0:00:00.017517 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 31/140 [00:00<00:02, 46.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.022507: 0:00:00.018507 / 0:00:00.004000\n",
      "0:00:00.020505: 0:00:00.018505 / 0:00:00.002000\n",
      "0:00:00.022013: 0:00:00.019010 / 0:00:00.003003\n",
      "0:00:00.021507: 0:00:00.017511 / 0:00:00.003996\n",
      "0:00:00.020002: 0:00:00.017002 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 36/140 [00:00<00:02, 46.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020507: 0:00:00.017505 / 0:00:00.003002\n",
      "0:00:00.021043: 0:00:00.019047 / 0:00:00.001996\n",
      "0:00:00.019118: 0:00:00.015118 / 0:00:00.004000\n",
      "0:00:00.021009: 0:00:00.016505 / 0:00:00.004504\n",
      "0:00:00.019509: 0:00:00.014510 / 0:00:00.004999\n",
      "0:00:00.024014: 0:00:00.019002 / 0:00:00.005012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 41/140 [00:00<00:02, 46.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021000: 0:00:00.018000 / 0:00:00.003000\n",
      "0:00:00.020009: 0:00:00.017009 / 0:00:00.003000\n",
      "0:00:00.019508: 0:00:00.016509 / 0:00:00.002999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▋      | 51/140 [00:01<00:01, 47.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020510: 0:00:00.017504 / 0:00:00.003006\n",
      "0:00:00.021025: 0:00:00.017026 / 0:00:00.003999\n",
      "0:00:00.020508: 0:00:00.017508 / 0:00:00.003000\n",
      "0:00:00.020015: 0:00:00.016015 / 0:00:00.004000\n",
      "0:00:00.020011: 0:00:00.015013 / 0:00:00.004998\n",
      "0:00:00.020004: 0:00:00.017005 / 0:00:00.002999\n",
      "0:00:00.021035: 0:00:00.017530 / 0:00:00.003505\n",
      "0:00:00.021505: 0:00:00.017505 / 0:00:00.004000\n",
      "0:00:00.020508: 0:00:00.017508 / 0:00:00.003000\n",
      "0:00:00.020614: 0:00:00.017612 / 0:00:00.003002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▎     | 61/140 [00:01<00:01, 47.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021103: 0:00:00.017104 / 0:00:00.003999\n",
      "0:00:00.020505: 0:00:00.017505 / 0:00:00.003000\n",
      "0:00:00.021013: 0:00:00.016505 / 0:00:00.004508\n",
      "0:00:00.022014: 0:00:00.019015 / 0:00:00.002999\n",
      "0:00:00.021003: 0:00:00.018004 / 0:00:00.002999\n",
      "0:00:00.020508: 0:00:00.014506 / 0:00:00.006002\n",
      "0:00:00.021014: 0:00:00.018012 / 0:00:00.003002\n",
      "0:00:00.019510: 0:00:00.016513 / 0:00:00.002997\n",
      "0:00:00.020019: 0:00:00.016512 / 0:00:00.003507\n",
      "0:00:00.021509: 0:00:00.018508 / 0:00:00.003001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 71/140 [00:01<00:01, 48.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0:00:00.020002: 0:00:00.016003 / 0:00:00.003999\n",
      "0:00:00.020019: 0:00:00.015016 / 0:00:00.005003\n",
      "0:00:00.021021: 0:00:00.016025 / 0:00:00.004996\n",
      "0:00:00.020511: 0:00:00.016514 / 0:00:00.003997\n",
      "0:00:00.019506: 0:00:00.014506 / 0:00:00.005000\n",
      "0:00:00.021507: 0:00:00.017508 / 0:00:00.003999\n",
      "0:00:00.021001: 0:00:00.017003 / 0:00:00.003998\n",
      "0:00:00.021011: 0:00:00.018011 / 0:00:00.003000\n",
      "0:00:00.020023: 0:00:00.014005 / 0:00:00.006018\n",
      "0:00:00.020006: 0:00:00.015007 / 0:00:00.004999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 81/140 [00:01<00:01, 48.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.019511: 0:00:00.014513 / 0:00:00.004998\n",
      "0:00:00.019543: 0:00:00.014508 / 0:00:00.005035\n",
      "0:00:00.020516: 0:00:00.017515 / 0:00:00.003001\n",
      "0:00:00.022008: 0:00:00.019009 / 0:00:00.002999\n",
      "0:00:00.020510: 0:00:00.015004 / 0:00:00.005506\n",
      "0:00:00.019504: 0:00:00.015505 / 0:00:00.003999\n",
      "0:00:00.021035: 0:00:00.018035 / 0:00:00.003000\n",
      "0:00:00.021515: 0:00:00.017505 / 0:00:00.004010\n",
      "0:00:00.020004: 0:00:00.017004 / 0:00:00.003000\n",
      "0:00:00.020508: 0:00:00.018508 / 0:00:00.002000\n",
      "0:00:00.024017: 0:00:00.020017 / 0:00:00.004000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 91/140 [00:01<00:01, 48.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.019517: 0:00:00.016511 / 0:00:00.003006\n",
      "0:00:00.020505: 0:00:00.017505 / 0:00:00.003000\n",
      "0:00:00.021010: 0:00:00.017010 / 0:00:00.004000\n",
      "0:00:00.020004: 0:00:00.017003 / 0:00:00.003001\n",
      "0:00:00.020014: 0:00:00.016012 / 0:00:00.004002\n",
      "0:00:00.020575: 0:00:00.015513 / 0:00:00.005062\n",
      "0:00:00.022506: 0:00:00.019506 / 0:00:00.003000\n",
      "0:00:00.020503: 0:00:00.015504 / 0:00:00.004999\n",
      "0:00:00.020013: 0:00:00.016507 / 0:00:00.003506\n",
      "0:00:00.021005: 0:00:00.017004 / 0:00:00.004001\n",
      "0:00:00.020015: 0:00:00.017015 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 106/140 [00:02<00:00, 48.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021516: 0:00:00.017008 / 0:00:00.004508\n",
      "0:00:00.020002: 0:00:00.017001 / 0:00:00.003001\n",
      "0:00:00.020537: 0:00:00.017539 / 0:00:00.002998\n",
      "0:00:00.020018: 0:00:00.015512 / 0:00:00.004506\n",
      "0:00:00.020505: 0:00:00.015504 / 0:00:00.005001\n",
      "0:00:00.020508: 0:00:00.015510 / 0:00:00.004998\n",
      "0:00:00.019508: 0:00:00.016003 / 0:00:00.003505\n",
      "0:00:00.020513: 0:00:00.017514 / 0:00:00.002999\n",
      "0:00:00.021032: 0:00:00.016030 / 0:00:00.005002\n",
      "0:00:00.019506: 0:00:00.016507 / 0:00:00.002999\n",
      "0:00:00.021519: 0:00:00.017516 / 0:00:00.004003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 116/140 [00:02<00:00, 48.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020503: 0:00:00.016502 / 0:00:00.004001\n",
      "0:00:00.019004: 0:00:00.015007 / 0:00:00.003997\n",
      "0:00:00.020028: 0:00:00.017030 / 0:00:00.002998\n",
      "0:00:00.021018: 0:00:00.018017 / 0:00:00.003001\n",
      "0:00:00.020504: 0:00:00.017505 / 0:00:00.002999\n",
      "0:00:00.020509: 0:00:00.017507 / 0:00:00.003002\n",
      "0:00:00.020507: 0:00:00.015507 / 0:00:00.005000\n",
      "0:00:00.019005: 0:00:00.014008 / 0:00:00.004997\n",
      "0:00:00.023514: 0:00:00.020010 / 0:00:00.003504\n",
      "0:00:00.021508: 0:00:00.019507 / 0:00:00.002001\n",
      "0:00:00.021001: 0:00:00.018001 / 0:00:00.003000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 126/140 [00:02<00:00, 48.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.020023: 0:00:00.017020 / 0:00:00.003003\n",
      "0:00:00.021023: 0:00:00.019023 / 0:00:00.002000\n",
      "0:00:00.020001: 0:00:00.017004 / 0:00:00.002997\n",
      "0:00:00.020007: 0:00:00.017008 / 0:00:00.002999\n",
      "0:00:00.021503: 0:00:00.017504 / 0:00:00.003999\n",
      "0:00:00.019505: 0:00:00.017505 / 0:00:00.002000\n",
      "0:00:00.020011: 0:00:00.017009 / 0:00:00.003002\n",
      "0:00:00.021017: 0:00:00.015017 / 0:00:00.006000\n",
      "0:00:00.019002: 0:00:00.015002 / 0:00:00.004000\n",
      "0:00:00.021013: 0:00:00.015506 / 0:00:00.005507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 136/140 [00:02<00:00, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.021512: 0:00:00.017515 / 0:00:00.003997\n",
      "0:00:00.025012: 0:00:00.021505 / 0:00:00.003507\n",
      "0:00:00.022001: 0:00:00.019001 / 0:00:00.003000\n",
      "0:00:00.021503: 0:00:00.016507 / 0:00:00.004996\n",
      "0:00:00.019507: 0:00:00.017002 / 0:00:00.002505\n",
      "0:00:00.021508: 0:00:00.018004 / 0:00:00.003504\n",
      "0:00:00.020507: 0:00:00.017508 / 0:00:00.002999\n",
      "0:00:00.021015: 0:00:00.016508 / 0:00:00.004507\n",
      "0:00:00.020000: 0:00:00.016001 / 0:00:00.003999\n",
      "0:00:00.019507: 0:00:00.016507 / 0:00:00.003000\n",
      "0:00:00.020013: 0:00:00.016003 / 0:00:00.004010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 140/140 [00:03<00:00, 46.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.019507: 0:00:00.016504 / 0:00:00.003003\n",
      "\n",
      "time to prep x_d 0:00:00.026601s\n",
      "time to warp and decode 0:00:03.010739s\n",
      "time to transfer pinned to cpu 0:00:00\n",
      "total generation time 0:00:03.037340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_frames = process_motion_batch8(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream frame by frame\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def process_motion_stream(gen_motion_batch, motion_prev, f_s, x_s, warp_decode_func, output_buffer):\n",
    "    # Process generated motion feature\n",
    "    generated_motion = torch.cat([motion_prev[0], gen_motion_batch.reshape(-1, gen_motion_batch.shape[-1])], dim = 0)\n",
    "    full_motion = torch.zeros(generated_motion.shape[0], 63, device = device)\n",
    "    full_motion[:, audio_model_config['latent_mask_1']] = generated_motion\n",
    "\n",
    "    # Process generated x_d (full motion feature)\n",
    "    pitch = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    yaw = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    roll = torch.zeros((1), dtype = torch.float32, device = device)\n",
    "    scale = torch.ones((1), dtype = torch.float32, device = device) * 1.5\n",
    "    base_pose = x_c_s @ get_rotation_matrix(pitch, yaw, roll)\n",
    "    x_d_batch = (scale * (base_pose + full_motion.reshape(-1, 21, 3))).squeeze(0)\n",
    "    #output_buffer = torch.zeros((x_d_batch.shape[0], 512, 512, 3), dtype = torch.uint8, pin_memory = True)\n",
    "\n",
    "    # Process frame\n",
    "    for i in range(x_d_batch.shape[0]):\n",
    "        # Step 1 process current frame through the warp_decode_func\n",
    "        out = warp_decode_func(f_s, x_s, x_d_batch[i].unsqueeze(0))\n",
    "\n",
    "        # Step 2 write to output pinned memory buffer\n",
    "        output_buffer.put(out['out'].permute(0, 2, 3, 1).mul_(255).to(torch.uint8).squeeze(0))\n",
    "\n",
    "    # Terminate\n",
    "    output_buffer.put(None)\n",
    "\n",
    "def display_frames(output_buffer, pre_time):\n",
    "    while True:\n",
    "        # Retrieve the next frame from the buffer\n",
    "        frame_tensor = output_buffer.get()\n",
    "\n",
    "        # End of processing\n",
    "        if frame_tensor is None:\n",
    "            break\n",
    "\n",
    "        # Transfer the frame from pinned memory back to CPU\n",
    "        frame = frame_tensor.cpu().numpy()\n",
    "        result_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Ensure 25 fps\n",
    "        if (datetime.now() - pre_time).total_seconds() < 0.024:\n",
    "            sleep(0.024 - (datetime.now() - pre_time).total_seconds())\n",
    "\n",
    "        # Display the frame using OpenCV\n",
    "        print(f\"time to display {datetime.now() - pre_time}\")\n",
    "        cv2.imshow(\"Video Stream\", result_bgr)\n",
    "        cv2.waitKey(1)\n",
    "        pre_time = datetime.now()\n",
    "\n",
    "def stream_frames(generated_motion, motion_prev, f_s, x_s, warp_decode):\n",
    "    # Record start time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Output buffer tracking\n",
    "    output_buffer = Queue(maxsize = 5000)\n",
    "\n",
    "    # Start frame processing thread\n",
    "    processing_thread = Thread(target = process_motion_stream, args=(generated_motion, motion_prev, f_s, x_s, warp_decode, output_buffer))\n",
    "    processing_thread.start()\n",
    "\n",
    "    # Start display frame\n",
    "    display_frames(output_buffer, start_time)\n",
    "\n",
    "    # Wait until terminate\n",
    "    processing_thread.join()\n",
    "\n",
    "    # Cleanup\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to display 0:00:00.122051\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025203\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024527\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024527\n",
      "time to display 0:00:00.025046\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024574\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025046\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.025023\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024535\n",
      "time to display 0:00:00.024552\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025074\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025065\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.025132\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024590\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024457\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024519\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025197\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024629\n",
      "time to display 0:00:00.024537\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025090\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024553\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.024603\n",
      "time to display 0:00:00.025034\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025082\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024519\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025027\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025018\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024537\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024615\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024585\n",
      "time to display 0:00:00.024291\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025020\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024529\n",
      "time to display 0:00:00.024558\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025171\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024542\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024533\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025023\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024597\n",
      "time to display 0:00:00.024448\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024954\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024501\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025000\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025178\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.024665\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024501\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024681\n",
      "time to display 0:00:00.024607\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025035\n",
      "time to display 0:00:00.025043\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024530\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024522\n",
      "time to display 0:00:00.025101\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024524\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024534\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024574\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024010\n",
      "time to display 0:00:00.024650\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025069\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025026\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024573\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025037\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024522\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024543\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024523\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025055\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024523\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025102\n",
      "time to display 0:00:00.024519\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024533\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025038\n",
      "time to display 0:00:00.025033\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025064\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025028\n",
      "time to display 0:00:00.024018\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024529\n",
      "time to display 0:00:00.024106\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024521\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024519\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024573\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025018\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024697\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025000\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024444\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024501\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025000\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024524\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.024503\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024548\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024521\n",
      "time to display 0:00:00.024570\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025036\n",
      "time to display 0:00:00.025051\n",
      "time to display 0:00:00.024018\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024522\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024704\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024601\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024595\n",
      "time to display 0:00:00.024427\n",
      "time to display 0:00:00.025027\n",
      "time to display 0:00:00.025085\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025168\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.024549\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025040\n",
      "time to display 0:00:00.024528\n",
      "time to display 0:00:00.025049\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.024521\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024601\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025047\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024532\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025361\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024532\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024545\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025064\n",
      "time to display 0:00:00.024521\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025023\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024524\n",
      "time to display 0:00:00.025021\n",
      "time to display 0:00:00.025039\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024532\n",
      "time to display 0:00:00.025023\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024857\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024519\n",
      "time to display 0:00:00.025027\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025024\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.024529\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024852\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024518\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025034\n",
      "time to display 0:00:00.024447\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025053\n",
      "time to display 0:00:00.025234\n",
      "time to display 0:00:00.025052\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024936\n",
      "time to display 0:00:00.025203\n",
      "time to display 0:00:00.024884\n",
      "time to display 0:00:00.024893\n",
      "time to display 0:00:00.024619\n",
      "time to display 0:00:00.025184\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.024986\n",
      "time to display 0:00:00.025028\n",
      "time to display 0:00:00.024841\n",
      "time to display 0:00:00.024939\n",
      "time to display 0:00:00.025066\n",
      "time to display 0:00:00.024021\n",
      "time to display 0:00:00.025000\n",
      "time to display 0:00:00.024847\n",
      "time to display 0:00:00.024614\n",
      "time to display 0:00:00.025085\n",
      "time to display 0:00:00.024956\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.024868\n",
      "time to display 0:00:00.024527\n",
      "time to display 0:00:00.025154\n",
      "time to display 0:00:00.024152\n",
      "time to display 0:00:00.024440\n",
      "time to display 0:00:00.025103\n",
      "time to display 0:00:00.024927\n",
      "time to display 0:00:00.024323\n",
      "time to display 0:00:00.024661\n",
      "time to display 0:00:00.024257\n",
      "time to display 0:00:00.025138\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025050\n",
      "time to display 0:00:00.024563\n",
      "time to display 0:00:00.024325\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.025068\n",
      "time to display 0:00:00.025455\n",
      "time to display 0:00:00.025561\n",
      "time to display 0:00:00.025058\n",
      "time to display 0:00:00.024898\n",
      "time to display 0:00:00.024731\n",
      "time to display 0:00:00.025033\n",
      "time to display 0:00:00.024934\n",
      "time to display 0:00:00.024941\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024109\n",
      "time to display 0:00:00.024530\n",
      "time to display 0:00:00.025049\n",
      "time to display 0:00:00.025286\n",
      "time to display 0:00:00.024915\n",
      "time to display 0:00:00.024857\n",
      "time to display 0:00:00.024980\n",
      "time to display 0:00:00.024077\n",
      "time to display 0:00:00.024405\n",
      "time to display 0:00:00.024712\n",
      "time to display 0:00:00.024941\n",
      "time to display 0:00:00.025080\n",
      "time to display 0:00:00.025319\n",
      "time to display 0:00:00.024992\n",
      "time to display 0:00:00.025367\n",
      "time to display 0:00:00.024914\n",
      "time to display 0:00:00.025376\n",
      "time to display 0:00:00.025049\n",
      "time to display 0:00:00.025121\n",
      "time to display 0:00:00.024900\n",
      "time to display 0:00:00.024864\n",
      "time to display 0:00:00.025235\n",
      "time to display 0:00:00.024526\n",
      "time to display 0:00:00.024486\n",
      "time to display 0:00:00.024077\n",
      "time to display 0:00:00.024095\n",
      "time to display 0:00:00.024195\n",
      "time to display 0:00:00.024441\n",
      "time to display 0:00:00.024115\n",
      "time to display 0:00:00.025032\n",
      "time to display 0:00:00.025062\n",
      "time to display 0:00:00.025060\n",
      "time to display 0:00:00.025020\n",
      "time to display 0:00:00.024580\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024416\n",
      "time to display 0:00:00.025237\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025050\n",
      "time to display 0:00:00.024566\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024528\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025081\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.025020\n",
      "time to display 0:00:00.025029\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.024522\n",
      "time to display 0:00:00.024525\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024842\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.025234\n",
      "time to display 0:00:00.024884\n",
      "time to display 0:00:00.025329\n",
      "time to display 0:00:00.025268\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025086\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025078\n",
      "time to display 0:00:00.025060\n",
      "time to display 0:00:00.025232\n",
      "time to display 0:00:00.025120\n",
      "time to display 0:00:00.024427\n",
      "time to display 0:00:00.025364\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.025094\n",
      "time to display 0:00:00.024022\n",
      "time to display 0:00:00.024580\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025022\n",
      "time to display 0:00:00.024516\n",
      "time to display 0:00:00.024594\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025099\n",
      "time to display 0:00:00.025021\n",
      "time to display 0:00:00.024997\n",
      "time to display 0:00:00.025101\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025266\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024651\n",
      "time to display 0:00:00.024552\n",
      "time to display 0:00:00.024564\n",
      "time to display 0:00:00.025060\n",
      "time to display 0:00:00.025287\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.025007\n",
      "time to display 0:00:00.025201\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024606\n",
      "time to display 0:00:00.024514\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024223\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024023\n",
      "time to display 0:00:00.024019\n",
      "time to display 0:00:00.024130\n",
      "time to display 0:00:00.024583\n",
      "time to display 0:00:00.024554\n",
      "time to display 0:00:00.025342\n",
      "time to display 0:00:00.024615\n",
      "time to display 0:00:00.024556\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.025060\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.025200\n",
      "time to display 0:00:00.025072\n",
      "time to display 0:00:00.025019\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.024923\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.024515\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025100\n",
      "time to display 0:00:00.025084\n",
      "time to display 0:00:00.024513\n",
      "time to display 0:00:00.025076\n",
      "time to display 0:00:00.025059\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.025270\n",
      "time to display 0:00:00.025063\n",
      "time to display 0:00:00.024059\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025455\n",
      "time to display 0:00:00.024941\n",
      "time to display 0:00:00.025278\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025024\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024523\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.024508\n",
      "time to display 0:00:00.024465\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024875\n",
      "time to display 0:00:00.025022\n",
      "time to display 0:00:00.024555\n",
      "time to display 0:00:00.024021\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025065\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025072\n",
      "time to display 0:00:00.025160\n",
      "time to display 0:00:00.024517\n",
      "time to display 0:00:00.025055\n",
      "time to display 0:00:00.025059\n",
      "time to display 0:00:00.025064\n",
      "time to display 0:00:00.025406\n",
      "time to display 0:00:00.024079\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024509\n",
      "time to display 0:00:00.024577\n",
      "time to display 0:00:00.024524\n",
      "time to display 0:00:00.025026\n",
      "time to display 0:00:00.024506\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025108\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.024573\n",
      "time to display 0:00:00.025179\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.025021\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.025147\n",
      "time to display 0:00:00.025017\n",
      "time to display 0:00:00.025067\n",
      "time to display 0:00:00.024940\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025023\n",
      "time to display 0:00:00.025067\n",
      "time to display 0:00:00.025058\n",
      "time to display 0:00:00.024031\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.024512\n",
      "time to display 0:00:00.025028\n",
      "time to display 0:00:00.024520\n",
      "time to display 0:00:00.024481\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024511\n",
      "time to display 0:00:00.024302\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.025059\n",
      "time to display 0:00:00.024454\n",
      "time to display 0:00:00.024522\n",
      "time to display 0:00:00.025033\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.024507\n",
      "time to display 0:00:00.024510\n",
      "time to display 0:00:00.025008\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025006\n",
      "time to display 0:00:00.025004\n",
      "time to display 0:00:00.024998\n",
      "time to display 0:00:00.025025\n",
      "time to display 0:00:00.024998\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025002\n",
      "time to display 0:00:00.024505\n",
      "time to display 0:00:00.024013\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.024504\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.024134\n",
      "time to display 0:00:00.024567\n",
      "time to display 0:00:00.025005\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.024502\n",
      "time to display 0:00:00.025009\n",
      "time to display 0:00:00.025012\n",
      "time to display 0:00:00.025001\n",
      "time to display 0:00:00.025013\n",
      "time to display 0:00:00.024255\n",
      "time to display 0:00:00.025517\n",
      "time to display 0:00:00.025010\n",
      "time to display 0:00:00.025011\n",
      "time to display 0:00:00.025099\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025015\n",
      "time to display 0:00:00.025014\n",
      "time to display 0:00:00.025370\n",
      "time to display 0:00:00.024561\n",
      "time to display 0:00:00.025016\n",
      "time to display 0:00:00.025021\n",
      "time to display 0:00:00.025060\n",
      "time to display 0:00:00.025027\n",
      "time to display 0:00:00.024977\n",
      "time to display 0:00:00.025263\n",
      "time to display 0:00:00.024871\n",
      "time to display 0:00:00.024947\n",
      "time to display 0:00:00.025031\n",
      "time to display 0:00:00.024902\n",
      "time to display 0:00:00.024857\n",
      "time to display 0:00:00.024964\n",
      "time to display 0:00:00.025182\n",
      "time to display 0:00:00.025086\n",
      "time to display 0:00:00.025024\n",
      "time to display 0:00:00.024136\n",
      "time to display 0:00:00.024531\n",
      "time to display 0:00:00.024955\n",
      "time to display 0:00:00.025062\n",
      "time to display 0:00:00.025003\n",
      "time to display 0:00:00.024962\n",
      "time to display 0:00:00.024880\n",
      "time to display 0:00:00.025267\n",
      "time to display 0:00:00.025301\n",
      "time to display 0:00:00.024905\n",
      "time to display 0:00:00.025232\n",
      "time to display 0:00:00.024143\n",
      "time to display 0:00:00.025033\n",
      "time to display 0:00:00.024023\n",
      "time to display 0:00:00.024067\n",
      "time to display 0:00:00.024535\n",
      "time to display 0:00:00.025286\n",
      "time to display 0:00:00.024805\n",
      "time to display 0:00:00.024246\n",
      "time to display 0:00:00.024637\n",
      "time to display 0:00:00.024572\n"
     ]
    }
   ],
   "source": [
    "stream_frames(generated_motion, motion_prev, f_s, x_s, warp_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with audio saved to D:/Projects/Upenn_CIS_5650/final-project/LivePortrait/inference/animations/test5_with_audio.mp4\n"
     ]
    }
   ],
   "source": [
    "# Save as MP4\n",
    "\n",
    "# Remove the files if they exist\n",
    "if os.path.exists(output_no_audio_path):\n",
    "    os.remove(output_no_audio_path)\n",
    "if os.path.exists(output_video):\n",
    "    os.remove(output_video)\n",
    "fps = 25  # Adjust as needed\n",
    "\n",
    "height, width, layers = all_frames[0].shape\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(output_no_audio_path, fourcc, fps, (width, height))\n",
    "\n",
    "for frame in all_frames:\n",
    "    video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Add audio to the video using ffmpeg\n",
    "input_video = output_no_audio_path\n",
    "input_audio = used_audio_example  # Use the path to your audio file\n",
    "\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg',\n",
    "    '-i', input_video,\n",
    "    '-i', input_audio,\n",
    "    '-c:v', 'copy',\n",
    "    '-c:a', 'aac',\n",
    "    '-shortest',\n",
    "    output_video\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(ffmpeg_cmd, check=True)\n",
    "    os.remove(output_no_audio_path)\n",
    "    print(f\"Video with audio saved to {output_video}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error adding audio to video: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
