{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:05:59] </span>LandmarkRunner warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.</span>487s                                                 <a href=\"file:///mnt/e/wsl_projects/LivePortrait/src/utils/landmark_runner.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">landmark_runner.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/e/wsl_projects/LivePortrait/src/utils/landmark_runner.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11:05:59]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m3.\u001b[0m487s                                                 \u001b]8;id=562591;file:///mnt/e/wsl_projects/LivePortrait/src/utils/landmark_runner.py\u001b\\\u001b[2mlandmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=458954;file:///mnt/e/wsl_projects/LivePortrait/src/utils/landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:06:01] </span>FaceAnalysisDIY warmup time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>612s                                              <a href=\"file:///mnt/e/wsl_projects/LivePortrait/src/utils/face_analysis_diy.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">face_analysis_diy.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/e/wsl_projects/LivePortrait/src/utils/face_analysis_diy.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11:06:01]\u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m1.\u001b[0m612s                                              \u001b]8;id=8195;file:///mnt/e/wsl_projects/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=332961;file:///mnt/e/wsl_projects/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import tyro\n",
    "import subprocess\n",
    "from rich.progress import track\n",
    "import torchvision\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import torchvision.transforms as transforms\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import imageio\n",
    "\n",
    "from src.config.argument_config import ArgumentConfig\n",
    "from src.config.inference_config import InferenceConfig\n",
    "from src.config.crop_config import CropConfig\n",
    "\n",
    "def partial_fields(target_class, kwargs):\n",
    "    return target_class(**{k: v for k, v in kwargs.items() if hasattr(target_class, k)})\n",
    "\n",
    "args = ArgumentConfig()\n",
    "inference_cfg = partial_fields(InferenceConfig, args.__dict__)\n",
    "crop_cfg = partial_fields(CropConfig, args.__dict__)\n",
    "# print(\"inference_cfg: \", inference_cfg)\n",
    "# print(\"crop_cfg: \", crop_cfg)\n",
    "device = 'cuda'\n",
    "print(\"Compile complete\")\n",
    "\n",
    "'''\n",
    "Common modules\n",
    "'''\n",
    "\n",
    "from src.utils.helper import load_model, concat_feat\n",
    "from src.utils.camera import headpose_pred_to_degree, get_rotation_matrix\n",
    "from src.utils.retargeting_utils import calc_eye_close_ratio, calc_lip_close_ratio\n",
    "from src.config.inference_config import InferenceConfig\n",
    "from src.utils.cropper import Cropper\n",
    "from src.utils.camera import get_rotation_matrix\n",
    "from src.utils.video import images2video, concat_frames, get_fps, add_audio_to_video, has_audio_stream\n",
    "from src.utils.crop import _transform_img, prepare_paste_back, paste_back\n",
    "from src.utils.io import load_image_rgb, load_video, resize_to_limit, dump, load\n",
    "from src.utils.helper import mkdir, basename, dct2device, is_video, is_template, remove_suffix, is_image\n",
    "from src.utils.filter import smooth\n",
    "\n",
    "\n",
    "'''\n",
    "Util functions\n",
    "'''\n",
    "\n",
    "def calculate_distance_ratio(lmk: np.ndarray, idx1: int, idx2: int, idx3: int, idx4: int, eps: float = 1e-6) -> np.ndarray:\n",
    "    return (np.linalg.norm(lmk[:, idx1] - lmk[:, idx2], axis=1, keepdims=True) /\n",
    "            (np.linalg.norm(lmk[:, idx3] - lmk[:, idx4], axis=1, keepdims=True) + eps))\n",
    "\n",
    "\n",
    "def calc_eye_close_ratio(lmk: np.ndarray, target_eye_ratio: np.ndarray = None) -> np.ndarray:\n",
    "    lefteye_close_ratio = calculate_distance_ratio(lmk, 6, 18, 0, 12)\n",
    "    righteye_close_ratio = calculate_distance_ratio(lmk, 30, 42, 24, 36)\n",
    "    if target_eye_ratio is not None:\n",
    "        return np.concatenate([lefteye_close_ratio, righteye_close_ratio, target_eye_ratio], axis=1)\n",
    "    else:\n",
    "        return np.concatenate([lefteye_close_ratio, righteye_close_ratio], axis=1)\n",
    "\n",
    "\n",
    "def calc_lip_close_ratio(lmk: np.ndarray) -> np.ndarray:\n",
    "    return calculate_distance_ratio(lmk, 90, 102, 48, 66)\n",
    "\n",
    "def calc_ratio(lmk_lst):\n",
    "    input_eye_ratio_lst = []\n",
    "    input_lip_ratio_lst = []\n",
    "    for lmk in lmk_lst:\n",
    "        # for eyes retargeting\n",
    "        input_eye_ratio_lst.append(calc_eye_close_ratio(lmk[None]))\n",
    "        # for lip retargeting\n",
    "        input_lip_ratio_lst.append(calc_lip_close_ratio(lmk[None]))\n",
    "    return input_eye_ratio_lst, input_lip_ratio_lst\n",
    "\n",
    "def prepare_videos_(imgs, device):\n",
    "    \"\"\" construct the input as standard\n",
    "    imgs: NxHxWx3, uint8\n",
    "    \"\"\"\n",
    "    if isinstance(imgs, list):\n",
    "        _imgs = np.array(imgs)\n",
    "    elif isinstance(imgs, np.ndarray):\n",
    "        _imgs = imgs\n",
    "    else:\n",
    "        raise ValueError(f'imgs type error: {type(imgs)}')\n",
    "\n",
    "    # y = _imgs.astype(np.float32) / 255.\n",
    "    y = _imgs\n",
    "    y = torch.from_numpy(y).permute(0, 3, 1, 2)  # NxHxWx3 -> Nx3xHxW\n",
    "    y = y.to(device)\n",
    "    y = y / 255.\n",
    "    y = torch.clamp(y, 0, 1)\n",
    "\n",
    "    return y\n",
    "\n",
    "def get_kp_info(x: torch.Tensor, **kwargs) -> dict:\n",
    "    \"\"\" get the implicit keypoint information\n",
    "    x: Bx3xHxW, normalized to 0~1\n",
    "    flag_refine_info: whether to trandform the pose to degrees and the dimention of the reshape\n",
    "    return: A dict contains keys: 'pitch', 'yaw', 'roll', 't', 'exp', 'scale', 'kp'\n",
    "    \"\"\"\n",
    "    with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.float16,\n",
    "                                 enabled=inference_cfg.flag_use_half_precision):\n",
    "        kp_info = motion_extractor(x)\n",
    "\n",
    "        if inference_cfg.flag_use_half_precision:\n",
    "            # float the dict\n",
    "            for k, v in kp_info.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    kp_info[k] = v.float()\n",
    "\n",
    "    flag_refine_info: bool = kwargs.get('flag_refine_info', True)\n",
    "    if flag_refine_info:\n",
    "        bs = kp_info['kp'].shape[0]\n",
    "        kp_info['pitch'] = headpose_pred_to_degree(kp_info['pitch'])[:, None]  # Bx1\n",
    "        kp_info['yaw'] = headpose_pred_to_degree(kp_info['yaw'])[:, None]  # Bx1\n",
    "        kp_info['roll'] = headpose_pred_to_degree(kp_info['roll'])[:, None]  # Bx1\n",
    "        kp_info['kp'] = kp_info['kp'].reshape(bs, -1, 3)  # BxNx3\n",
    "        kp_info['exp'] = kp_info['exp'].reshape(bs, -1, 3)  # BxNx3\n",
    "\n",
    "    return kp_info\n",
    "\n",
    "def read_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frames = []\n",
    "    for _ in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (256, 256))  # Resize to 256x256\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return video_path, frames\n",
    "\n",
    "def read_multiple_videos(video_paths, num_threads=4):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = list(executor.map(read_video_frames, video_paths))\n",
    "    return results\n",
    "\n",
    "'''\n",
    "Main module for inference\n",
    "'''\n",
    "model_config = yaml.load(open(inference_cfg.models_config, 'r'), Loader=yaml.SafeLoader)\n",
    "# init F\n",
    "appearance_feature_extractor = load_model(inference_cfg.checkpoint_F, model_config, device, 'appearance_feature_extractor')\n",
    "# init M\n",
    "motion_extractor = load_model(inference_cfg.checkpoint_M, model_config, device, 'motion_extractor')\n",
    "# init W\n",
    "warping_module = load_model(inference_cfg.checkpoint_W, model_config, device, 'warping_module')\n",
    "# init G\n",
    "spade_generator = load_model(inference_cfg.checkpoint_G, model_config, device, 'spade_generator')\n",
    "# init S and R\n",
    "if inference_cfg.checkpoint_S is not None and os.path.exists(inference_cfg.checkpoint_S):\n",
    "    stitching_retargeting_module = load_model(inference_cfg.checkpoint_S, model_config, device, 'stitching_retargeting_module')\n",
    "else:\n",
    "    stitching_retargeting_module = None\n",
    "\n",
    "cropper = Cropper(crop_cfg=crop_cfg, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "video_dir = '/mnt/e/data/vox2/videos/512/id00774/'\n",
    "output_dir = '/mnt/c/Users/mjh/Downloads/out_test/'\n",
    "read_2_gpu_batch_size = 2048\n",
    "gpu_batch_size = 16\n",
    "file_processed_indx = 0\n",
    "process_queue = torch.Tensor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 video files.\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00001.mp4\n",
      "Processed video: 00001 - 0Noa8soq03Y, frames: 127\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00002.mp4\n",
      "Processed video: 00002 - 0Noa8soq03Y, frames: 109\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00003.mp4\n",
      "Processed video: 00003 - 0Noa8soq03Y, frames: 456\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00004.mp4\n",
      "Processed video: 00004 - 0Noa8soq03Y, frames: 114\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00005.mp4\n",
      "Processed video: 00005 - 0Noa8soq03Y, frames: 131\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00006.mp4\n",
      "Processed video: 00006 - 0Noa8soq03Y, frames: 548\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00007.mp4\n",
      "Processed video: 00007 - 0Noa8soq03Y, frames: 110\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00008.mp4\n",
      "Processed video: 00008 - 0Noa8soq03Y, frames: 223\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00009.mp4\n",
      "Processed video: 00009 - 0Noa8soq03Y, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00010.mp4\n",
      "Processed video: 00010 - 0Noa8soq03Y, frames: 106\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00011.mp4\n",
      "Processed video: 00011 - 0Noa8soq03Y, frames: 154\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00012.mp4\n",
      "Processed video: 00012 - 0Noa8soq03Y, frames: 357\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00014.mp4\n",
      "Processed video: 00014 - 0Noa8soq03Y, frames: 209\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00015.mp4\n",
      "Processed video: 00015 - 0Noa8soq03Y, frames: 196\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00016.mp4\n",
      "Processed video: 00016 - 0Noa8soq03Y, frames: 135\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00017.mp4\n",
      "Processed video: 00017 - 0Noa8soq03Y, frames: 146\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00018.mp4\n",
      "Processed video: 00018 - 0Noa8soq03Y, frames: 211\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00019.mp4\n",
      "Processed video: 00019 - 0Noa8soq03Y, frames: 277\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00020.mp4\n",
      "Processed video: 00020 - 0Noa8soq03Y, frames: 265\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00021.mp4\n",
      "Processed video: 00021 - 0Noa8soq03Y, frames: 121\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00022.mp4\n",
      "Processed video: 00022 - 0Noa8soq03Y, frames: 127\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00023.mp4\n",
      "Processed video: 00023 - 0Noa8soq03Y, frames: 286\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00024.mp4\n",
      "Processed video: 00024 - 0Noa8soq03Y, frames: 197\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00025.mp4\n",
      "Processed video: 00025 - 0Noa8soq03Y, frames: 129\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00026.mp4\n",
      "Processed video: 00026 - 0Noa8soq03Y, frames: 314\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00027.mp4\n",
      "Processed video: 00027 - 0Noa8soq03Y, frames: 112\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00028.mp4\n",
      "Processed video: 00028 - 0Noa8soq03Y, frames: 106\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00029.mp4\n",
      "Processed video: 00029 - 0Noa8soq03Y, frames: 122\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00030.mp4\n",
      "Processed video: 00030 - 0Noa8soq03Y, frames: 537\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00031.mp4\n",
      "Processed video: 00031 - 0Noa8soq03Y, frames: 316\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00032.mp4\n",
      "Processed video: 00032 - 0Noa8soq03Y, frames: 159\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00033.mp4\n",
      "Processed video: 00033 - 0Noa8soq03Y, frames: 125\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00034.mp4\n",
      "Processed video: 00034 - 0Noa8soq03Y, frames: 255\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00035.mp4\n",
      "Processed video: 00035 - 0Noa8soq03Y, frames: 167\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00036.mp4\n",
      "Processed video: 00036 - 0Noa8soq03Y, frames: 125\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00037.mp4\n",
      "Processed video: 00037 - 0Noa8soq03Y, frames: 139\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00038.mp4\n",
      "Processed video: 00038 - 0Noa8soq03Y, frames: 154\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00040.mp4\n",
      "Processed video: 00040 - 0Noa8soq03Y, frames: 142\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00041.mp4\n",
      "Processed video: 00041 - 0Noa8soq03Y, frames: 213\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00042.mp4\n",
      "Processed video: 00042 - 0Noa8soq03Y, frames: 101\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00043.mp4\n",
      "Processed video: 00043 - 0Noa8soq03Y, frames: 219\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00044.mp4\n",
      "Processed video: 00044 - 0Noa8soq03Y, frames: 119\n",
      "/mnt/e/data/vox2/videos/512/id00774/0Noa8soq03Y/00045.mp4\n",
      "Processed video: 00045 - 0Noa8soq03Y, frames: 164\n",
      "/mnt/e/data/vox2/videos/512/id00774/2LdIVgNTdXE/00047.mp4\n",
      "Processed video: 00047 - 2LdIVgNTdXE, frames: 174\n",
      "/mnt/e/data/vox2/videos/512/id00774/2LdIVgNTdXE/00048.mp4\n",
      "Processed video: 00048 - 2LdIVgNTdXE, frames: 321\n",
      "/mnt/e/data/vox2/videos/512/id00774/2LdIVgNTdXE/00050.mp4\n",
      "Processed video: 00050 - 2LdIVgNTdXE, frames: 692\n",
      "/mnt/e/data/vox2/videos/512/id00774/2LdIVgNTdXE/00051.mp4\n",
      "Processed video: 00051 - 2LdIVgNTdXE, frames: 354\n",
      "/mnt/e/data/vox2/videos/512/id00774/2LdIVgNTdXE/00052.mp4\n",
      "Processed video: 00052 - 2LdIVgNTdXE, frames: 165\n",
      "/mnt/e/data/vox2/videos/512/id00774/3WdNMVoiJZk/00054.mp4\n",
      "Processed video: 00054 - 3WdNMVoiJZk, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/8by_jrrfptY/00070.mp4\n",
      "Processed video: 00070 - 8by_jrrfptY, frames: 114\n",
      "/mnt/e/data/vox2/videos/512/id00774/8by_jrrfptY/00071.mp4\n",
      "Processed video: 00071 - 8by_jrrfptY, frames: 114\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00087.mp4\n",
      "Processed video: 00087 - 8kjb9gTbyYc, frames: 104\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00090.mp4\n",
      "Processed video: 00090 - 8kjb9gTbyYc, frames: 296\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00091.mp4\n",
      "Processed video: 00091 - 8kjb9gTbyYc, frames: 406\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00093.mp4\n",
      "Processed video: 00093 - 8kjb9gTbyYc, frames: 114\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00094.mp4\n",
      "Processed video: 00094 - 8kjb9gTbyYc, frames: 256\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00096.mp4\n",
      "Processed video: 00096 - 8kjb9gTbyYc, frames: 426\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00097.mp4\n",
      "Processed video: 00097 - 8kjb9gTbyYc, frames: 231\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00099.mp4\n",
      "Processed video: 00099 - 8kjb9gTbyYc, frames: 136\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00101.mp4\n",
      "Processed video: 00101 - 8kjb9gTbyYc, frames: 272\n",
      "/mnt/e/data/vox2/videos/512/id00774/8kjb9gTbyYc/00106.mp4\n",
      "Processed video: 00106 - 8kjb9gTbyYc, frames: 290\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00110.mp4\n",
      "Processed video: 00110 - FFo6yZHv2uQ, frames: 221\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00111.mp4\n",
      "Processed video: 00111 - FFo6yZHv2uQ, frames: 316\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00112.mp4\n",
      "Processed video: 00112 - FFo6yZHv2uQ, frames: 224\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00115.mp4\n",
      "Processed video: 00115 - FFo6yZHv2uQ, frames: 473\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00116.mp4\n",
      "Processed video: 00116 - FFo6yZHv2uQ, frames: 293\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00117.mp4\n",
      "Processed video: 00117 - FFo6yZHv2uQ, frames: 126\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00120.mp4\n",
      "Processed video: 00120 - FFo6yZHv2uQ, frames: 118\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00121.mp4\n",
      "Processed video: 00121 - FFo6yZHv2uQ, frames: 356\n",
      "/mnt/e/data/vox2/videos/512/id00774/FFo6yZHv2uQ/00123.mp4\n",
      "Processed video: 00123 - FFo6yZHv2uQ, frames: 381\n",
      "/mnt/e/data/vox2/videos/512/id00774/HhGAogrgF5E/00138.mp4\n",
      "Processed video: 00138 - HhGAogrgF5E, frames: 131\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00149.mp4\n",
      "Processed video: 00149 - M-NgKXcDcSg, frames: 221\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00150.mp4\n",
      "Processed video: 00150 - M-NgKXcDcSg, frames: 412\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00153.mp4\n",
      "Processed video: 00153 - M-NgKXcDcSg, frames: 392\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00155.mp4\n",
      "Processed video: 00155 - M-NgKXcDcSg, frames: 216\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00156.mp4\n",
      "Processed video: 00156 - M-NgKXcDcSg, frames: 307\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00158.mp4\n",
      "Processed video: 00158 - M-NgKXcDcSg, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00160.mp4\n",
      "Processed video: 00160 - M-NgKXcDcSg, frames: 170\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00162.mp4\n",
      "Processed video: 00162 - M-NgKXcDcSg, frames: 172\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00163.mp4\n",
      "Processed video: 00163 - M-NgKXcDcSg, frames: 597\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00165.mp4\n",
      "Processed video: 00165 - M-NgKXcDcSg, frames: 322\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00166.mp4\n",
      "Processed video: 00166 - M-NgKXcDcSg, frames: 157\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00167.mp4\n",
      "Processed video: 00167 - M-NgKXcDcSg, frames: 202\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00168.mp4\n",
      "Processed video: 00168 - M-NgKXcDcSg, frames: 164\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00169.mp4\n",
      "Processed video: 00169 - M-NgKXcDcSg, frames: 568\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00170.mp4\n",
      "Processed video: 00170 - M-NgKXcDcSg, frames: 289\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00171.mp4\n",
      "Processed video: 00171 - M-NgKXcDcSg, frames: 377\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00174.mp4\n",
      "Processed video: 00174 - M-NgKXcDcSg, frames: 273\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00175.mp4\n",
      "Processed video: 00175 - M-NgKXcDcSg, frames: 297\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00176.mp4\n",
      "Processed video: 00176 - M-NgKXcDcSg, frames: 302\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00180.mp4\n",
      "Processed video: 00180 - M-NgKXcDcSg, frames: 199\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00181.mp4\n",
      "Processed video: 00181 - M-NgKXcDcSg, frames: 483\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00182.mp4\n",
      "Processed video: 00182 - M-NgKXcDcSg, frames: 103\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00184.mp4\n",
      "Processed video: 00184 - M-NgKXcDcSg, frames: 584\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00186.mp4\n",
      "Processed video: 00186 - M-NgKXcDcSg, frames: 507\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00187.mp4\n",
      "Processed video: 00187 - M-NgKXcDcSg, frames: 313\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00189.mp4\n",
      "Processed video: 00189 - M-NgKXcDcSg, frames: 300\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00190.mp4\n",
      "Processed video: 00190 - M-NgKXcDcSg, frames: 184\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00191.mp4\n",
      "Processed video: 00191 - M-NgKXcDcSg, frames: 111\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00192.mp4\n",
      "Processed video: 00192 - M-NgKXcDcSg, frames: 135\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00194.mp4\n",
      "Processed video: 00194 - M-NgKXcDcSg, frames: 126\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00195.mp4\n",
      "Processed video: 00195 - M-NgKXcDcSg, frames: 134\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00196.mp4\n",
      "Processed video: 00196 - M-NgKXcDcSg, frames: 266\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00197.mp4\n",
      "Processed video: 00197 - M-NgKXcDcSg, frames: 260\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00198.mp4\n",
      "Processed video: 00198 - M-NgKXcDcSg, frames: 482\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00200.mp4\n",
      "Processed video: 00200 - M-NgKXcDcSg, frames: 337\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00202.mp4\n",
      "Processed video: 00202 - M-NgKXcDcSg, frames: 322\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00203.mp4\n",
      "Processed video: 00203 - M-NgKXcDcSg, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00204.mp4\n",
      "Processed video: 00204 - M-NgKXcDcSg, frames: 670\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00206.mp4\n",
      "Processed video: 00206 - M-NgKXcDcSg, frames: 204\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00207.mp4\n",
      "Processed video: 00207 - M-NgKXcDcSg, frames: 177\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00208.mp4\n",
      "Processed video: 00208 - M-NgKXcDcSg, frames: 154\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00210.mp4\n",
      "Processed video: 00210 - M-NgKXcDcSg, frames: 181\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00212.mp4\n",
      "Processed video: 00212 - M-NgKXcDcSg, frames: 669\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00213.mp4\n",
      "Processed video: 00213 - M-NgKXcDcSg, frames: 425\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00214.mp4\n",
      "Processed video: 00214 - M-NgKXcDcSg, frames: 113\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00215.mp4\n",
      "Processed video: 00215 - M-NgKXcDcSg, frames: 182\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00218.mp4\n",
      "Processed video: 00218 - M-NgKXcDcSg, frames: 158\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00219.mp4\n",
      "Processed video: 00219 - M-NgKXcDcSg, frames: 177\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00221.mp4\n",
      "Processed video: 00221 - M-NgKXcDcSg, frames: 149\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00223.mp4\n",
      "Processed video: 00223 - M-NgKXcDcSg, frames: 383\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00224.mp4\n",
      "Processed video: 00224 - M-NgKXcDcSg, frames: 262\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00225.mp4\n",
      "Processed video: 00225 - M-NgKXcDcSg, frames: 157\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00227.mp4\n",
      "Processed video: 00227 - M-NgKXcDcSg, frames: 229\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00228.mp4\n",
      "Processed video: 00228 - M-NgKXcDcSg, frames: 291\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00229.mp4\n",
      "Processed video: 00229 - M-NgKXcDcSg, frames: 118\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00232.mp4\n",
      "Processed video: 00232 - M-NgKXcDcSg, frames: 123\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00233.mp4\n",
      "Processed video: 00233 - M-NgKXcDcSg, frames: 580\n",
      "/mnt/e/data/vox2/videos/512/id00774/M-NgKXcDcSg/00234.mp4\n",
      "Processed video: 00234 - M-NgKXcDcSg, frames: 256\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00243.mp4\n",
      "Processed video: 00243 - TDfdmb8vqag, frames: 106\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00244.mp4\n",
      "Processed video: 00244 - TDfdmb8vqag, frames: 160\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00245.mp4\n",
      "Processed video: 00245 - TDfdmb8vqag, frames: 108\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00246.mp4\n",
      "Processed video: 00246 - TDfdmb8vqag, frames: 130\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00247.mp4\n",
      "Processed video: 00247 - TDfdmb8vqag, frames: 365\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00248.mp4\n",
      "Processed video: 00248 - TDfdmb8vqag, frames: 302\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00249.mp4\n",
      "Processed video: 00249 - TDfdmb8vqag, frames: 191\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00250.mp4\n",
      "Processed video: 00250 - TDfdmb8vqag, frames: 164\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00251.mp4\n",
      "Processed video: 00251 - TDfdmb8vqag, frames: 182\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00252.mp4\n",
      "Processed video: 00252 - TDfdmb8vqag, frames: 146\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00253.mp4\n",
      "Processed video: 00253 - TDfdmb8vqag, frames: 204\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00254.mp4\n",
      "Processed video: 00254 - TDfdmb8vqag, frames: 181\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00255.mp4\n",
      "Processed video: 00255 - TDfdmb8vqag, frames: 120\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00256.mp4\n",
      "Processed video: 00256 - TDfdmb8vqag, frames: 244\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00257.mp4\n",
      "Processed video: 00257 - TDfdmb8vqag, frames: 157\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00258.mp4\n",
      "Processed video: 00258 - TDfdmb8vqag, frames: 255\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00259.mp4\n",
      "Processed video: 00259 - TDfdmb8vqag, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00260.mp4\n",
      "Processed video: 00260 - TDfdmb8vqag, frames: 159\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00261.mp4\n",
      "Processed video: 00261 - TDfdmb8vqag, frames: 149\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00262.mp4\n",
      "Processed video: 00262 - TDfdmb8vqag, frames: 142\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00263.mp4\n",
      "Processed video: 00263 - TDfdmb8vqag, frames: 196\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00264.mp4\n",
      "Processed video: 00264 - TDfdmb8vqag, frames: 175\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00265.mp4\n",
      "Processed video: 00265 - TDfdmb8vqag, frames: 162\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00266.mp4\n",
      "Processed video: 00266 - TDfdmb8vqag, frames: 133\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00267.mp4\n",
      "Processed video: 00267 - TDfdmb8vqag, frames: 254\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00268.mp4\n",
      "Processed video: 00268 - TDfdmb8vqag, frames: 203\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00269.mp4\n",
      "Processed video: 00269 - TDfdmb8vqag, frames: 133\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00270.mp4\n",
      "Processed video: 00270 - TDfdmb8vqag, frames: 333\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00271.mp4\n",
      "Processed video: 00271 - TDfdmb8vqag, frames: 361\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00272.mp4\n",
      "Processed video: 00272 - TDfdmb8vqag, frames: 101\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00273.mp4\n",
      "Processed video: 00273 - TDfdmb8vqag, frames: 131\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00274.mp4\n",
      "Processed video: 00274 - TDfdmb8vqag, frames: 100\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00275.mp4\n",
      "Processed video: 00275 - TDfdmb8vqag, frames: 362\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00276.mp4\n",
      "Processed video: 00276 - TDfdmb8vqag, frames: 361\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00277.mp4\n",
      "Processed video: 00277 - TDfdmb8vqag, frames: 162\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00278.mp4\n",
      "Processed video: 00278 - TDfdmb8vqag, frames: 177\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00279.mp4\n",
      "Processed video: 00279 - TDfdmb8vqag, frames: 272\n",
      "/mnt/e/data/vox2/videos/512/id00774/TDfdmb8vqag/00280.mp4\n",
      "Processed video: 00280 - TDfdmb8vqag, frames: 234\n",
      "/mnt/e/data/vox2/videos/512/id00774/W5NghVuEE7o/00286.mp4\n",
      "Processed video: 00286 - W5NghVuEE7o, frames: 249\n",
      "/mnt/e/data/vox2/videos/512/id00774/W5NghVuEE7o/00288.mp4\n",
      "Processed video: 00288 - W5NghVuEE7o, frames: 254\n",
      "/mnt/e/data/vox2/videos/512/id00774/W5NghVuEE7o/00289.mp4\n",
      "Processed video: 00289 - W5NghVuEE7o, frames: 158\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00300.mp4\n",
      "Processed video: 00300 - Zg87o0xGGVU, frames: 233\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00301.mp4\n",
      "Processed video: 00301 - Zg87o0xGGVU, frames: 185\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00302.mp4\n",
      "Processed video: 00302 - Zg87o0xGGVU, frames: 275\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00303.mp4\n",
      "Processed video: 00303 - Zg87o0xGGVU, frames: 153\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00304.mp4\n",
      "Processed video: 00304 - Zg87o0xGGVU, frames: 118\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00305.mp4\n",
      "Processed video: 00305 - Zg87o0xGGVU, frames: 180\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00306.mp4\n",
      "Processed video: 00306 - Zg87o0xGGVU, frames: 378\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00307.mp4\n",
      "Processed video: 00307 - Zg87o0xGGVU, frames: 124\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00310.mp4\n",
      "Processed video: 00310 - Zg87o0xGGVU, frames: 268\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00311.mp4\n",
      "Processed video: 00311 - Zg87o0xGGVU, frames: 1255\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00312.mp4\n",
      "Processed video: 00312 - Zg87o0xGGVU, frames: 213\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00313.mp4\n",
      "Processed video: 00313 - Zg87o0xGGVU, frames: 268\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00315.mp4\n",
      "Processed video: 00315 - Zg87o0xGGVU, frames: 102\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00316.mp4\n",
      "Processed video: 00316 - Zg87o0xGGVU, frames: 197\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00317.mp4\n",
      "Processed video: 00317 - Zg87o0xGGVU, frames: 162\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00318.mp4\n",
      "Processed video: 00318 - Zg87o0xGGVU, frames: 176\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00319.mp4\n",
      "Processed video: 00319 - Zg87o0xGGVU, frames: 101\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00320.mp4\n",
      "Processed video: 00320 - Zg87o0xGGVU, frames: 278\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00321.mp4\n",
      "Processed video: 00321 - Zg87o0xGGVU, frames: 105\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00322.mp4\n",
      "Processed video: 00322 - Zg87o0xGGVU, frames: 224\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00323.mp4\n",
      "Processed video: 00323 - Zg87o0xGGVU, frames: 558\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00325.mp4\n",
      "Processed video: 00325 - Zg87o0xGGVU, frames: 292\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00326.mp4\n",
      "Processed video: 00326 - Zg87o0xGGVU, frames: 119\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00327.mp4\n",
      "Processed video: 00327 - Zg87o0xGGVU, frames: 240\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00328.mp4\n",
      "Processed video: 00328 - Zg87o0xGGVU, frames: 207\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00330.mp4\n",
      "Processed video: 00330 - Zg87o0xGGVU, frames: 385\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00331.mp4\n",
      "Processed video: 00331 - Zg87o0xGGVU, frames: 148\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00332.mp4\n",
      "Processed video: 00332 - Zg87o0xGGVU, frames: 310\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00333.mp4\n",
      "Processed video: 00333 - Zg87o0xGGVU, frames: 205\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00334.mp4\n",
      "Processed video: 00334 - Zg87o0xGGVU, frames: 309\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00335.mp4\n",
      "Processed video: 00335 - Zg87o0xGGVU, frames: 252\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00336.mp4\n",
      "Processed video: 00336 - Zg87o0xGGVU, frames: 146\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00337.mp4\n",
      "Processed video: 00337 - Zg87o0xGGVU, frames: 192\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00338.mp4\n",
      "Processed video: 00338 - Zg87o0xGGVU, frames: 320\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00339.mp4\n",
      "Processed video: 00339 - Zg87o0xGGVU, frames: 234\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00341.mp4\n",
      "Processed video: 00341 - Zg87o0xGGVU, frames: 111\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00342.mp4\n",
      "Processed video: 00342 - Zg87o0xGGVU, frames: 328\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00343.mp4\n",
      "Processed video: 00343 - Zg87o0xGGVU, frames: 229\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00344.mp4\n",
      "Processed video: 00344 - Zg87o0xGGVU, frames: 138\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00345.mp4\n",
      "Processed video: 00345 - Zg87o0xGGVU, frames: 273\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00346.mp4\n",
      "Processed video: 00346 - Zg87o0xGGVU, frames: 150\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00347.mp4\n",
      "Processed video: 00347 - Zg87o0xGGVU, frames: 130\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00348.mp4\n",
      "Processed video: 00348 - Zg87o0xGGVU, frames: 115\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00349.mp4\n",
      "Processed video: 00349 - Zg87o0xGGVU, frames: 106\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00350.mp4\n",
      "Processed video: 00350 - Zg87o0xGGVU, frames: 109\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00351.mp4\n",
      "Processed video: 00351 - Zg87o0xGGVU, frames: 192\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00356.mp4\n",
      "Processed video: 00356 - Zg87o0xGGVU, frames: 155\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00357.mp4\n",
      "Processed video: 00357 - Zg87o0xGGVU, frames: 114\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00358.mp4\n",
      "Processed video: 00358 - Zg87o0xGGVU, frames: 117\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00360.mp4\n",
      "Processed video: 00360 - Zg87o0xGGVU, frames: 211\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00362.mp4\n",
      "Processed video: 00362 - Zg87o0xGGVU, frames: 192\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00363.mp4\n",
      "Processed video: 00363 - Zg87o0xGGVU, frames: 244\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00364.mp4\n",
      "Processed video: 00364 - Zg87o0xGGVU, frames: 266\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00365.mp4\n",
      "Processed video: 00365 - Zg87o0xGGVU, frames: 136\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00366.mp4\n",
      "Processed video: 00366 - Zg87o0xGGVU, frames: 128\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00368.mp4\n",
      "Processed video: 00368 - Zg87o0xGGVU, frames: 579\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00369.mp4\n",
      "Processed video: 00369 - Zg87o0xGGVU, frames: 518\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00372.mp4\n",
      "Processed video: 00372 - Zg87o0xGGVU, frames: 518\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00374.mp4\n",
      "Processed video: 00374 - Zg87o0xGGVU, frames: 105\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00375.mp4\n",
      "Processed video: 00375 - Zg87o0xGGVU, frames: 165\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00377.mp4\n",
      "Processed video: 00377 - Zg87o0xGGVU, frames: 172\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00378.mp4\n",
      "Processed video: 00378 - Zg87o0xGGVU, frames: 249\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00379.mp4\n",
      "Processed video: 00379 - Zg87o0xGGVU, frames: 111\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00380.mp4\n",
      "Processed video: 00380 - Zg87o0xGGVU, frames: 100\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00381.mp4\n",
      "Processed video: 00381 - Zg87o0xGGVU, frames: 270\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00382.mp4\n",
      "Processed video: 00382 - Zg87o0xGGVU, frames: 152\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00386.mp4\n",
      "Processed video: 00386 - Zg87o0xGGVU, frames: 123\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00387.mp4\n",
      "Processed video: 00387 - Zg87o0xGGVU, frames: 185\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00388.mp4\n",
      "Processed video: 00388 - Zg87o0xGGVU, frames: 543\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00389.mp4\n",
      "Processed video: 00389 - Zg87o0xGGVU, frames: 170\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00390.mp4\n",
      "Processed video: 00390 - Zg87o0xGGVU, frames: 137\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00391.mp4\n",
      "Processed video: 00391 - Zg87o0xGGVU, frames: 504\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00392.mp4\n",
      "Processed video: 00392 - Zg87o0xGGVU, frames: 260\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00393.mp4\n",
      "Processed video: 00393 - Zg87o0xGGVU, frames: 140\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00394.mp4\n",
      "Processed video: 00394 - Zg87o0xGGVU, frames: 557\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00395.mp4\n",
      "Processed video: 00395 - Zg87o0xGGVU, frames: 202\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00396.mp4\n",
      "Processed video: 00396 - Zg87o0xGGVU, frames: 165\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00398.mp4\n",
      "Processed video: 00398 - Zg87o0xGGVU, frames: 108\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00399.mp4\n",
      "Processed video: 00399 - Zg87o0xGGVU, frames: 159\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00400.mp4\n",
      "Processed video: 00400 - Zg87o0xGGVU, frames: 150\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00402.mp4\n",
      "Processed video: 00402 - Zg87o0xGGVU, frames: 248\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00403.mp4\n",
      "Processed video: 00403 - Zg87o0xGGVU, frames: 253\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00404.mp4\n",
      "Processed video: 00404 - Zg87o0xGGVU, frames: 169\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00405.mp4\n",
      "Processed video: 00405 - Zg87o0xGGVU, frames: 221\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00407.mp4\n",
      "Processed video: 00407 - Zg87o0xGGVU, frames: 502\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00408.mp4\n",
      "Processed video: 00408 - Zg87o0xGGVU, frames: 215\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00410.mp4\n",
      "Processed video: 00410 - Zg87o0xGGVU, frames: 729\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00412.mp4\n",
      "Processed video: 00412 - Zg87o0xGGVU, frames: 177\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00413.mp4\n",
      "Processed video: 00413 - Zg87o0xGGVU, frames: 513\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00414.mp4\n",
      "Processed video: 00414 - Zg87o0xGGVU, frames: 197\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00416.mp4\n",
      "Processed video: 00416 - Zg87o0xGGVU, frames: 113\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00417.mp4\n",
      "Processed video: 00417 - Zg87o0xGGVU, frames: 420\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00418.mp4\n",
      "Processed video: 00418 - Zg87o0xGGVU, frames: 288\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00419.mp4\n",
      "Processed video: 00419 - Zg87o0xGGVU, frames: 112\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00420.mp4\n",
      "Processed video: 00420 - Zg87o0xGGVU, frames: 442\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00421.mp4\n",
      "Processed video: 00421 - Zg87o0xGGVU, frames: 213\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00422.mp4\n",
      "Processed video: 00422 - Zg87o0xGGVU, frames: 146\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00423.mp4\n",
      "Processed video: 00423 - Zg87o0xGGVU, frames: 214\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00424.mp4\n",
      "Processed video: 00424 - Zg87o0xGGVU, frames: 237\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00426.mp4\n",
      "Processed video: 00426 - Zg87o0xGGVU, frames: 115\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00427.mp4\n",
      "Processed video: 00427 - Zg87o0xGGVU, frames: 298\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00428.mp4\n",
      "Processed video: 00428 - Zg87o0xGGVU, frames: 108\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00429.mp4\n",
      "Processed video: 00429 - Zg87o0xGGVU, frames: 309\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00430.mp4\n",
      "Processed video: 00430 - Zg87o0xGGVU, frames: 456\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00431.mp4\n",
      "Processed video: 00431 - Zg87o0xGGVU, frames: 162\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00435.mp4\n",
      "Processed video: 00435 - Zg87o0xGGVU, frames: 263\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00436.mp4\n",
      "Processed video: 00436 - Zg87o0xGGVU, frames: 126\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00438.mp4\n",
      "Processed video: 00438 - Zg87o0xGGVU, frames: 553\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00439.mp4\n",
      "Processed video: 00439 - Zg87o0xGGVU, frames: 111\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00440.mp4\n",
      "Processed video: 00440 - Zg87o0xGGVU, frames: 351\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00441.mp4\n",
      "Processed video: 00441 - Zg87o0xGGVU, frames: 108\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00442.mp4\n",
      "Processed video: 00442 - Zg87o0xGGVU, frames: 441\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00445.mp4\n",
      "Processed video: 00445 - Zg87o0xGGVU, frames: 148\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00447.mp4\n",
      "Processed video: 00447 - Zg87o0xGGVU, frames: 209\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00450.mp4\n",
      "Processed video: 00450 - Zg87o0xGGVU, frames: 345\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00452.mp4\n",
      "Processed video: 00452 - Zg87o0xGGVU, frames: 773\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00453.mp4\n",
      "Processed video: 00453 - Zg87o0xGGVU, frames: 195\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00456.mp4\n",
      "Processed video: 00456 - Zg87o0xGGVU, frames: 137\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00457.mp4\n",
      "Processed video: 00457 - Zg87o0xGGVU, frames: 369\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00458.mp4\n",
      "Processed video: 00458 - Zg87o0xGGVU, frames: 135\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00459.mp4\n",
      "Processed video: 00459 - Zg87o0xGGVU, frames: 125\n",
      "/mnt/e/data/vox2/videos/512/id00774/Zg87o0xGGVU/00460.mp4\n",
      "Processed video: 00460 - Zg87o0xGGVU, frames: 224\n",
      "/mnt/e/data/vox2/videos/512/id00774/jZ0W1c8AO_M/00468.mp4\n",
      "Processed video: 00468 - jZ0W1c8AO_M, frames: 247\n",
      "/mnt/e/data/vox2/videos/512/id00774/jZ0W1c8AO_M/00470.mp4\n",
      "Processed video: 00470 - jZ0W1c8AO_M, frames: 408\n",
      "\n",
      "Total frames across all videos: 71013\n",
      "Video lengths: [127, 109, 456, 114, 131, 548, 110, 223, 169, 106, 154, 357, 209, 196, 135, 146, 211, 277, 265, 121, 127, 286, 197, 129, 314, 112, 106, 122, 537, 316, 159, 125, 255, 167, 125, 139, 154, 142, 213, 101, 219, 119, 164, 174, 321, 692, 354, 165, 169, 114, 114, 104, 296, 406, 114, 256, 426, 231, 136, 272, 290, 221, 316, 224, 473, 293, 126, 118, 356, 381, 131, 221, 412, 392, 216, 307, 169, 170, 172, 597, 322, 157, 202, 164, 568, 289, 377, 273, 297, 302, 199, 483, 103, 584, 507, 313, 300, 184, 111, 135, 126, 134, 266, 260, 482, 337, 322, 169, 670, 204, 177, 154, 181, 669, 425, 113, 182, 158, 177, 149, 383, 262, 157, 229, 291, 118, 123, 580, 256, 106, 160, 108, 130, 365, 302, 191, 164, 182, 146, 204, 181, 120, 244, 157, 255, 169, 159, 149, 142, 196, 175, 162, 133, 254, 203, 133, 333, 361, 101, 131, 100, 362, 361, 162, 177, 272, 234, 249, 254, 158, 233, 185, 275, 153, 118, 180, 378, 124, 268, 1255, 213, 268, 102, 197, 162, 176, 101, 278, 105, 224, 558, 292, 119, 240, 207, 385, 148, 310, 205, 309, 252, 146, 192, 320, 234, 111, 328, 229, 138, 273, 150, 130, 115, 106, 109, 192, 155, 114, 117, 211, 192, 244, 266, 136, 128, 579, 518, 518, 105, 165, 172, 249, 111, 100, 270, 152, 123, 185, 543, 170, 137, 504, 260, 140, 557, 202, 165, 108, 159, 150, 248, 253, 169, 221, 502, 215, 729, 177, 513, 197, 113, 420, 288, 112, 442, 213, 146, 214, 237, 115, 298, 108, 309, 456, 162, 263, 126, 553, 111, 351, 108, 441, 148, 209, 345, 773, 195, 137, 369, 135, 125, 224, 247, 408]\n",
      "Shape of concatenated array: (71013, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read all video files\n",
    "video_paths = sorted(glob.glob(os.path.join(video_dir, '**', '*.mp4'), recursive=True))  # Search recursively\n",
    "\n",
    "print(f\"Found {len(video_paths)} video files.\")\n",
    "\n",
    "video_frames = read_multiple_videos(video_paths, num_threads=4)\n",
    "all_frames = []\n",
    "total_frames = 0\n",
    "video_lengths = []\n",
    "vid_keys= []\n",
    "\n",
    "for video_path, frames in video_frames:\n",
    "    all_frames.extend(frames)\n",
    "    frame_count = len(frames)\n",
    "    total_frames += frame_count\n",
    "    video_lengths.append(frame_count)\n",
    "    print(video_path)\n",
    "    clip_id = video_path.split('/')[-1].split('.')[0]\n",
    "    url_id = video_path.split('/')[-2]\n",
    "    vid_keys.append(url_id+'+'+clip_id+'+'+str(frame_count))\n",
    "    print(f\"Processed video: {clip_id} - {url_id}, frames: {frame_count}\")\n",
    "\n",
    "print(f\"\\nTotal frames across all videos: {total_frames}\")\n",
    "print(f\"Video lengths: {video_lengths}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "all_frames = np.array(all_frames)\n",
    "\n",
    "print(f\"Shape of concatenated array: {all_frames.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/wsl_projects/vasa_unofficial/vasa_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2048 frames in 2.95 seconds. Saved 9 video files in 0.15 seconds.\n",
      "Processed 2048 frames in 1.64 seconds. Saved 10 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.65 seconds. Saved 10 video files in 0.15 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 11 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.57 seconds. Saved 8 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.56 seconds. Saved 9 video files in 0.09 seconds.\n",
      "Processed 2048 frames in 1.60 seconds. Saved 7 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.62 seconds. Saved 8 video files in 0.07 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 8 video files in 0.11 seconds.\n",
      "Processed 2048 frames in 1.67 seconds. Saved 6 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.65 seconds. Saved 7 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 9 video files in 0.13 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 6 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.57 seconds. Saved 6 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.51 seconds. Saved 10 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 9 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.58 seconds. Saved 11 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.57 seconds. Saved 11 video files in 0.07 seconds.\n",
      "Processed 2048 frames in 1.58 seconds. Saved 9 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.57 seconds. Saved 9 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.59 seconds. Saved 6 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.61 seconds. Saved 10 video files in 0.06 seconds.\n",
      "Processed 2048 frames in 1.60 seconds. Saved 7 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.64 seconds. Saved 9 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.55 seconds. Saved 12 video files in 0.09 seconds.\n",
      "Processed 2048 frames in 1.56 seconds. Saved 9 video files in 0.13 seconds.\n",
      "Processed 2048 frames in 1.59 seconds. Saved 8 video files in 0.05 seconds.\n",
      "Processed 2048 frames in 1.60 seconds. Saved 8 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.56 seconds. Saved 10 video files in 0.03 seconds.\n",
      "Processed 2048 frames in 1.65 seconds. Saved 6 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.60 seconds. Saved 7 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.60 seconds. Saved 8 video files in 0.02 seconds.\n",
      "Processed 2048 frames in 1.57 seconds. Saved 8 video files in 0.04 seconds.\n",
      "Processed 2048 frames in 1.52 seconds. Saved 7 video files in 0.03 seconds.\n",
      "Processed 1381 frames in 1.11 seconds. Saved 6 video files in 0.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "read_data_2_gpu = True\n",
    "total_frames = len(all_frames)\n",
    "read_data_2_gpu_pointer = 0\n",
    "all_process_time = 0\n",
    "all_write_time = 0\n",
    "\n",
    "while read_data_2_gpu:\n",
    "    start_process_time = time.time()\n",
    "    # Calculate the batch size for this iteration\n",
    "    current_batch_size = min(read_2_gpu_batch_size, total_frames - read_data_2_gpu_pointer)\n",
    "\n",
    "    # Read the next batch of frames\n",
    "    batch_input = all_frames[read_data_2_gpu_pointer:read_data_2_gpu_pointer + current_batch_size]\n",
    "    batch_input = prepare_videos_(batch_input, device)\n",
    "\n",
    "    # Process the batch in mini-batches\n",
    "    # prepare mini-batches varaiables\n",
    "    mini_batch_start = 0\n",
    "    all_info = []\n",
    "    while mini_batch_start < batch_input.shape[0]:\n",
    "        mini_batch_end = min(mini_batch_start + gpu_batch_size, batch_input.shape[0])\n",
    "        mini_batch = batch_input[mini_batch_start:mini_batch_end]\n",
    "\n",
    "        x_info = get_kp_info(mini_batch)\n",
    "\n",
    "        # Concatenate the tensors\n",
    "        concat_tensor = torch.cat([\n",
    "            x_info['exp'].reshape(mini_batch_end - mini_batch_start, -1),\n",
    "            x_info['t'],\n",
    "            torch.cat([x_info['pitch'], x_info['yaw'], x_info['roll']], dim=1),\n",
    "        ], dim=1)\n",
    "\n",
    "        all_info.append(concat_tensor)\n",
    "\n",
    "        mini_batch_start = mini_batch_end\n",
    "    all_info_tensor = torch.cat(all_info, dim=0)\n",
    "    all_process_time = time.time() - start_process_time\n",
    "\n",
    "    start_write_time = time.time()\n",
    "    # add to process queue\n",
    "    process_queue = torch.cat((process_queue, all_info_tensor), dim=0)\n",
    "    write_to_disk_count = 0\n",
    "    write_to_disk_flag = True\n",
    "    while write_to_disk_flag and len(vid_keys) > 0:\n",
    "        current_vid_key = vid_keys[0]\n",
    "        current_frame_count = video_lengths[0]\n",
    "\n",
    "        if len(process_queue) >= current_frame_count:\n",
    "            # We have enough frames to write a complete video file\n",
    "            video_tensor = process_queue[:current_frame_count]\n",
    "            # Save tensor to disk\n",
    "            # save_path = os.path.join(output_dir, f\"{current_vid_key}.pt\")\n",
    "            # torch.save(video_tensor, save_path)\n",
    "            # Save tensor to disk using numpy\n",
    "            save_path = os.path.join(output_dir, f\"{current_vid_key}.npy\")\n",
    "            np.save(save_path, video_tensor.cpu().numpy())\n",
    "\n",
    "            # Remove processed frames from queue\n",
    "            process_queue = process_queue[current_frame_count:]\n",
    "            # Remove processed video key\n",
    "            vid_keys.pop(0)\n",
    "            video_lengths.pop(0)\n",
    "\n",
    "            write_to_disk_count += 1\n",
    "        else:\n",
    "            # Not enough frames in the queue, exit the loop\n",
    "            write_to_disk_flag = False\n",
    "    all_write_time = time.time() - start_write_time\n",
    "    # Update pointers and counters\n",
    "    read_data_2_gpu_pointer += current_batch_size\n",
    "    file_processed_indx += current_batch_size\n",
    "\n",
    "    if read_data_2_gpu_pointer >= total_frames:\n",
    "        read_data_2_gpu = False\n",
    "\n",
    "    print(f\"Processed {current_batch_size} frames in {all_process_time:.2f} seconds. Saved {write_to_disk_count} video files in {all_write_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read json ( input UNION with audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4617 video paths.\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "json_path = '/mnt/c/Users/mjh/Downloads/output_union_512.json'\n",
    "root_dir = '/mnt/e/data/vox2/videos/512/'  # Replace this with your actual root directory\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "video_paths = {}\n",
    "\n",
    "# Iterate through the JSON structure\n",
    "for first_level_key in data:\n",
    "    video_paths[first_level_key] = []\n",
    "    for second_level_key in data[first_level_key]:\n",
    "        for third_level_key in data[first_level_key][second_level_key]:\n",
    "            third_level_key = third_level_key.split('.')[0]\n",
    "            # Construct the video path\n",
    "            video_path = os.path.join(root_dir, first_level_key, second_level_key, f\"{third_level_key}.mp4\")\n",
    "            video_paths[first_level_key].append(video_path)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Generated {len(video_paths)} video paths.\")\n",
    "print(len(video_paths['id00774']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_rgb_lst = all_frames[2000:2500]\n",
    "I_d_lst = prepare_videos_(driving_rgb_lst, device)\n",
    "I_d_lst = I_d_lst.unsqueeze(1)\n",
    "# I_d_lst = I_d_lst[0 : video_lengths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_d_lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start = 0\n",
    "all_info = []\n",
    "all_pose = []\n",
    "all_t = []\n",
    "all_scale = []\n",
    "all_exp = []\n",
    "\n",
    "def euler_to_quaternion(pitch, yaw, roll):\n",
    "    cy = torch.cos(yaw * 0.5)\n",
    "    sy = torch.sin(yaw * 0.5)\n",
    "    cp = torch.cos(pitch * 0.5)\n",
    "    sp = torch.sin(pitch * 0.5)\n",
    "    cr = torch.cos(roll * 0.5)\n",
    "    sr = torch.sin(roll * 0.5)\n",
    "\n",
    "    w = cr * cp * cy + sr * sp * sy\n",
    "    x = sr * cp * cy - cr * sp * sy\n",
    "    y = cr * sp * cy + sr * cp * sy\n",
    "    z = cr * cp * sy - sr * sp * cy\n",
    "\n",
    "    return torch.cat([w, x, y, z], dim=-1)\n",
    "\n",
    "def encode_euler_angles(pitch, yaw, roll):\n",
    "    return euler_to_quaternion(pitch, yaw, roll)\n",
    "\n",
    "while True:\n",
    "    batch_end = min(batch_start + batch_size, I_d_lst.shape[0])\n",
    "    I_d = I_d_lst[batch_start:batch_end]\n",
    "    I_d = I_d.squeeze(1)\n",
    "    x_info = get_kp_info(I_d)\n",
    "    # R_i = get_rotation_matrix(x_info['pitch'], x_info['yaw'], x_info['roll'])\n",
    "    # Encode the Euler angles\n",
    "    # encoded_angles = encode_euler_angles(x_info['pitch'], x_info['yaw'], x_info['roll'])\n",
    "\n",
    "\n",
    "    # Concatenate the tensors\n",
    "    concat_tensor = torch.cat([\n",
    "        # encoded_angles,\n",
    "        torch.cat([x_info['pitch'], x_info['yaw'], x_info['roll']], dim=1),\n",
    "        x_info['t'],\n",
    "        # x_info['scale'],\n",
    "        x_info['exp'].reshape(batch_end - batch_start, -1),\n",
    "    ], dim=1)\n",
    "\n",
    "    all_info.append(concat_tensor)\n",
    "    # all_pose.append(encoded_angles)\n",
    "    all_t.append(x_info['t'])\n",
    "    all_scale.append(x_info['scale'])\n",
    "    all_exp.append(x_info['exp'])\n",
    "\n",
    "    if batch_end == I_d_lst.shape[0]:\n",
    "        break\n",
    "\n",
    "    batch_start = batch_end\n",
    "\n",
    "# Concatenate all batches\n",
    "all_info_tensor = torch.cat(all_info, dim=0)\n",
    "all_pose_tensor = torch.cat(all_pose, dim=0)\n",
    "all_t_tensor = torch.cat(all_t, dim=0)\n",
    "all_scale_tensor = torch.cat(all_scale, dim=0)\n",
    "all_exp_tensor = torch.cat(all_exp, dim=0)\n",
    "\n",
    "print(f\"Shape of concatenated info tensor: {all_info_tensor.shape}\")\n",
    "print(f\"Shape of concatenated pose tensor: {all_pose_tensor.shape}\")\n",
    "print(f\"Shape of concatenated t tensor: {all_t_tensor.shape}\")\n",
    "print(f\"Shape of concatenated scale tensor: {all_scale_tensor.shape}\")\n",
    "print(f\"Shape of concatenated exp tensor: {all_exp_tensor.shape}\")\n",
    "print(f\"Expected shape for info tensor: [{I_d_lst.shape[0]}, 69]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pose tensor - Mean:\", all_pose_tensor.mean(), \"Variance:\", all_pose_tensor.var())\n",
    "print(\"Translation tensor - Mean:\", all_t_tensor.mean(), \"Variance:\", all_t_tensor.var())\n",
    "print(\"Scale tensor - Mean:\", all_scale_tensor.mean(), \"Variance:\", all_scale_tensor.var())\n",
    "print(\"Expression tensor - Mean:\", all_exp_tensor.mean(), \"Variance:\", all_exp_tensor.var())\n",
    "print(\"Info tensor - Mean:\", all_info_tensor.mean(), \"Variance:\", all_info_tensor.var())\n",
    "print(all_pose_tensor.min(),\n",
    "      all_pose_tensor.max())\n",
    "print(all_t_tensor.min(),\n",
    "      all_t_tensor.max())\n",
    "print(all_scale_tensor.min(),\n",
    "      all_scale_tensor.max())\n",
    "print(all_exp_tensor.min(),\n",
    "      all_exp_tensor.max())\n",
    "print(all_info_tensor.min(),\n",
    "      all_info_tensor.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distributions(tensors, titles):\n",
    "    fig, axs = plt.subplots(len(tensors), 1, figsize=(10, 5*len(tensors)))\n",
    "    for tensor, title, ax in zip(tensors, titles, axs):\n",
    "        ax.hist(tensor.cpu().numpy().flatten(), bins=50)\n",
    "        ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot original distributions\n",
    "plot_distributions([all_pose_tensor, all_t_tensor, all_scale_tensor, all_exp_tensor],\n",
    "                   ['Pose', 'Translation', 'Scale', 'Expression'])\n",
    "\n",
    "# Define normalization functions\n",
    "def z_score_normalize(tensor):\n",
    "    mean = tensor.mean()\n",
    "    std = tensor.std()\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def min_max_normalize(tensor, feature_range=(-1, 1)):\n",
    "    min_val = tensor.min()\n",
    "    max_val = tensor.max()\n",
    "    scale = (feature_range[1] - feature_range[0]) / (max_val - min_val)\n",
    "    return (tensor - min_val) * scale + feature_range[0]\n",
    "\n",
    "def robust_normalize(tensor):\n",
    "    median = tensor.median()\n",
    "    q1 = tensor.quantile(0.25)\n",
    "    q3 = tensor.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return (tensor - median) / iqr\n",
    "\n",
    "# Apply different normalizations\n",
    "z_score_tensors = [z_score_normalize(t) for t in [all_pose_tensor, all_t_tensor, all_scale_tensor, all_exp_tensor]]\n",
    "min_max_tensors = [min_max_normalize(t) for t in [all_pose_tensor, all_t_tensor, all_scale_tensor, all_exp_tensor]]\n",
    "robust_tensors = [robust_normalize(t) for t in [all_pose_tensor, all_t_tensor, all_scale_tensor, all_exp_tensor]]\n",
    "\n",
    "# Plot normalized distributions\n",
    "plot_distributions(z_score_tensors, ['Z-score Pose', 'Z-score Translation', 'Z-score Scale', 'Z-score Expression'])\n",
    "plot_distributions(min_max_tensors, ['Min-Max Pose', 'Min-Max Translation', 'Min-Max Scale', 'Min-Max Expression'])\n",
    "plot_distributions(robust_tensors, ['Robust Pose', 'Robust Translation', 'Robust Scale', 'Robust Expression'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = I_d_lst.shape[0]\n",
    "template_dct = {\n",
    "    'n_frames': n_frames,\n",
    "    'output_fps': 25,\n",
    "    'motion': [],\n",
    "    'c_d_eyes_lst': [],\n",
    "    'c_d_lip_lst': [],\n",
    "    'x_i_info_lst': [],\n",
    "}\n",
    "\n",
    "for i in (range(n_frames)):\n",
    "    # collect s, R, δ and t for inference\n",
    "    I_i = I_d_lst[i]\n",
    "    x_i_info = get_kp_info(I_i)\n",
    "    R_i = get_rotation_matrix(x_i_info['pitch'], x_i_info['yaw'], x_i_info['roll'])\n",
    "\n",
    "    item_dct = {\n",
    "        'scale': x_i_info['scale'].cpu().numpy().astype(np.float32),\n",
    "        'R': R_i.cpu().numpy().astype(np.float32),\n",
    "        'exp': x_i_info['exp'].cpu().numpy().astype(np.float32),\n",
    "        't': x_i_info['t'].cpu().numpy().astype(np.float32),\n",
    "    }\n",
    "\n",
    "    template_dct['motion'].append(item_dct)\n",
    "\n",
    "    # c_eyes = c_d_eyes_lst[i].astype(np.float32)\n",
    "    # template_dct['c_d_eyes_lst'].append(c_eyes)\n",
    "\n",
    "    # c_lip = c_d_lip_lst[i].astype(np.float32)\n",
    "    # template_dct['c_d_lip_lst'].append(c_lip)\n",
    "\n",
    "    template_dct['x_i_info_lst'].append(x_i_info)\n",
    "    # print(f'frame {i} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def angular_distance(pose1, pose2):\n",
    "    diff = torch.abs(pose1 - pose2)\n",
    "    diff = torch.min(diff, 2*torch.pi - diff)\n",
    "    return torch.norm(diff)\n",
    "\n",
    "def find_dominant_pose(poses):\n",
    "    N = poses.shape[0]\n",
    "    total_distances = torch.zeros(N, device=poses.device)\n",
    "    for i in range(N):\n",
    "        distances = angular_distance(poses[i].unsqueeze(0), poses)\n",
    "        total_distances[i] = torch.sum(distances)\n",
    "    min_distance_index = torch.argmin(total_distances)\n",
    "    return poses[min_distance_index], min_distance_index\n",
    "\n",
    "# Prepare data\n",
    "n_frames = len(template_dct['motion'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Collect all poses and t values\n",
    "all_poses = torch.zeros(n_frames, 3, device=device)\n",
    "all_t = torch.zeros(n_frames, 3, device=device)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    info = template_dct['x_i_info_lst'][i]\n",
    "    roll, pitch, yaw = info['roll'], info['pitch'], info['yaw']\n",
    "    all_poses[i] = torch.tensor([roll, pitch, yaw], device=device).squeeze()\n",
    "    all_t[i] = torch.tensor(template_dct['motion'][i]['t'], device=device)\n",
    "\n",
    "# Find dominant pose\n",
    "dominant_pose, _ = find_dominant_pose( )\n",
    "\n",
    "# Find median t\n",
    "median_t = torch.median(all_t, dim=0).values\n",
    "\n",
    "# Subtract dominant pose and median t from the sequence\n",
    "for i in range(n_frames):\n",
    "    # Update pose\n",
    "    template_dct['x_i_info_lst'][i]['roll'] = (all_poses[i, 0]  - 1 * dominant_pose[0]).unsqueeze(0)\n",
    "    template_dct['x_i_info_lst'][i]['pitch'] = (all_poses[i, 1] - 1 * dominant_pose[1]).unsqueeze(0)\n",
    "    template_dct['x_i_info_lst'][i]['yaw'] = (all_poses[i, 2]   - 1 * dominant_pose[2]).unsqueeze(0)\n",
    "\n",
    "    # Update t\n",
    "    template_dct['motion'][i]['t'] = (all_t[i] - median_t).cpu().numpy()\n",
    "\n",
    "    # Recalculate R with the updated pose\n",
    "    new_R = get_rotation_matrix(\n",
    "        template_dct['x_i_info_lst'][i]['pitch'],\n",
    "        template_dct['x_i_info_lst'][i]['yaw'],\n",
    "        template_dct['x_i_info_lst'][i]['roll']\n",
    "    )\n",
    "    template_dct['motion'][i]['R'] = new_R.cpu().numpy()\n",
    "\n",
    "print(f\"Dominant pose (roll, pitch, yaw): {dominant_pose.cpu().numpy()}\")\n",
    "print(f\"Median t: {median_t.cpu().numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vasa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
